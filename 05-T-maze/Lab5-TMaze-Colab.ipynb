{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q7S9cpFJqfXy"
   },
   "source": [
    "## Julia on Colaboratory ##\n",
    "\n",
    "[Colaboratory](https://colab.research.google.com) does not provide native support for the [Julia programming language](https://julialang.org). However, since Colaboratory gives you root access to the machine that runs your notebook (the *“runtime”* in Colaboratory terminology), we can install Julia support by uploading a specially crafted Julia notebook  – *this* notebook. We then install Julia and [IJulia](https://github.com/JuliaLang/IJulia.jl) ([Jupyter](https://jupyter.org)/Colaboratory notebook support) and reload the notebook so that Colaboratory detects and initiates what we installed.\n",
    "\n",
    "In brief:\n",
    "\n",
    "1. **Run the cell below**\n",
    "2. **Reload the page**\n",
    "3. **Edit the notebook name and start hacking Julia code below**\n",
    "\n",
    "**If your runtime resets**, either manually or if left idle for some time, **repeat steps 1 and 2**.\n",
    "\n",
    "### Acknowledgements ###\n",
    "\n",
    "This hack by Pontus Stenetorp is an adaptation of [James Bradbury’s original Colaboratory Julia hack](https://discourse.julialang.org/t/julia-on-google-colab-free-gpu-accelerated-shareable-notebooks/15319/27), that broke some time in September 2019 as Colaboratory increased their level of notebook runtime isolation. There also appears to be CUDA compilation support installed by default for each notebook runtime type in October 2019, which shaves off a good 15 minutes or so from the original hack’s installation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BrHjOFFsxf7W",
    "outputId": "45e27bbb-c424-4538-f8c4-67fd0aea8925"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-08 07:50:27--  https://julialang-s3.julialang.org/bin/linux/x64/1.3/julia-1.3.1-linux-x86_64.tar.gz\n",
      "Resolving julialang-s3.julialang.org (julialang-s3.julialang.org)... 151.101.2.49, 151.101.66.49, 151.101.130.49, ...\n",
      "Connecting to julialang-s3.julialang.org (julialang-s3.julialang.org)|151.101.2.49|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 gce internal redirect trigger\n",
      "Location: https://storage.googleapis.com/julialang2/bin/linux/x64/1.3/julia-1.3.1-linux-x86_64.tar.gz [following]\n",
      "--2020-05-08 07:50:27--  https://storage.googleapis.com/julialang2/bin/linux/x64/1.3/julia-1.3.1-linux-x86_64.tar.gz\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.119.128, 2a00:1450:4013:c08::80\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.119.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 95929584 (91M) [application/x-gzip]\n",
      "Saving to: ‘/tmp/julia.tar.gz’\n",
      "\n",
      "/tmp/julia.tar.gz   100%[===================>]  91.49M  68.9MB/s    in 1.3s    \n",
      "\n",
      "2020-05-08 07:50:28 (68.9 MB/s) - ‘/tmp/julia.tar.gz’ saved [95929584/95929584]\n",
      "\n",
      "   Cloning default registries into `~/.julia`\n",
      "   Cloning registry from \"https://github.com/JuliaRegistries/General.git\"\n",
      "\u001b[2K\u001b[?25h     Added registry `General` to `~/.julia/registries/General`\n",
      " Resolving package versions...\n",
      " Installed x265_jll ─────────── v3.0.0+1\n",
      " Installed NaNMath ──────────── v0.3.3\n",
      " Installed libvorbis_jll ────── v1.3.6+4\n",
      " Installed Bzip2_jll ────────── v1.0.6+2\n",
      " Installed LibVPX_jll ───────── v1.8.1+1\n",
      " Installed PlotUtils ────────── v1.0.2\n",
      " Installed StatsBase ────────── v0.33.0\n",
      " Installed Plots ────────────── v1.2.2\n",
      " Installed FriBidi_jll ──────── v1.0.5+3\n",
      " Installed Measures ─────────── v0.3.1\n",
      " Installed DataAPI ──────────── v1.3.0\n",
      " Installed FFMPEG ───────────── v0.3.0\n",
      " Installed PlotThemes ───────── v2.0.0\n",
      " Installed Showoff ──────────── v0.3.1\n",
      " Installed Requires ─────────── v1.0.1\n",
      " Installed OpenSSL_jll ──────── v1.1.1+2\n",
      " Installed GeometryTypes ────── v0.8.3\n",
      " Installed StaticArrays ─────── v0.12.3\n",
      " Installed RecipesBase ──────── v1.0.1\n",
      " Installed FreeType2_jll ────── v2.10.1+2\n",
      " Installed DataStructures ───── v0.17.15\n",
      " Installed x264_jll ─────────── v2019.5.25+2\n",
      " Installed Zlib_jll ─────────── v1.2.11+9\n",
      " Installed FixedPointNumbers ── v0.8.0\n",
      " Installed Parsers ──────────── v1.0.3\n",
      " Installed SortingAlgorithms ── v0.3.1\n",
      " Installed ColorTypes ───────── v0.10.3\n",
      " Installed Reexport ─────────── v0.2.0\n",
      " Installed JSON ─────────────── v0.21.0\n",
      " Installed FFMPEG_jll ───────── v4.1.0+3\n",
      " Installed OrderedCollections ─ v1.2.0\n",
      " Installed libfdk_aac_jll ───── v0.1.6+2\n",
      " Installed Colors ───────────── v0.12.0\n",
      " Installed libass_jll ───────── v0.14.0+2\n",
      " Installed RecipesPipeline ──── v0.1.7\n",
      " Installed Ogg_jll ──────────── v1.3.4+0\n",
      " Installed LAME_jll ─────────── v3.100.0+1\n",
      " Installed Opus_jll ─────────── v1.3.1+1\n",
      " Installed GR ───────────────── v0.49.1\n",
      " Installed Missings ─────────── v0.4.3\n",
      " Installed Contour ──────────── v0.5.2\n",
      " Installed ColorSchemes ─────── v3.9.0\n",
      "  Updating `~/.julia/environments/v1.3/Project.toml`\n",
      "  [91a5bcdd] + Plots v1.2.2\n",
      "  Updating `~/.julia/environments/v1.3/Manifest.toml`\n",
      "  [6e34b625] + Bzip2_jll v1.0.6+2\n",
      "  [35d6a980] + ColorSchemes v3.9.0\n",
      "  [3da002f7] + ColorTypes v0.10.3\n",
      "  [5ae59095] + Colors v0.12.0\n",
      "  [d38c429a] + Contour v0.5.2\n",
      "  [9a962f9c] + DataAPI v1.3.0\n",
      "  [864edb3b] + DataStructures v0.17.15\n",
      "  [c87230d0] + FFMPEG v0.3.0\n",
      "  [b22a6f82] + FFMPEG_jll v4.1.0+3\n",
      "  [53c48c17] + FixedPointNumbers v0.8.0\n",
      "  [d7e528f0] + FreeType2_jll v2.10.1+2\n",
      "  [559328eb] + FriBidi_jll v1.0.5+3\n",
      "  [28b8d3ca] + GR v0.49.1\n",
      "  [4d00f742] + GeometryTypes v0.8.3\n",
      "  [682c06a0] + JSON v0.21.0\n",
      "  [c1c5ebd0] + LAME_jll v3.100.0+1\n",
      "  [dd192d2f] + LibVPX_jll v1.8.1+1\n",
      "  [442fdcdd] + Measures v0.3.1\n",
      "  [e1d29d7a] + Missings v0.4.3\n",
      "  [77ba4419] + NaNMath v0.3.3\n",
      "  [e7412a2a] + Ogg_jll v1.3.4+0\n",
      "  [458c3c95] + OpenSSL_jll v1.1.1+2\n",
      "  [91d4177d] + Opus_jll v1.3.1+1\n",
      "  [bac558e1] + OrderedCollections v1.2.0\n",
      "  [69de0a69] + Parsers v1.0.3\n",
      "  [ccf2f8ad] + PlotThemes v2.0.0\n",
      "  [995b91a9] + PlotUtils v1.0.2\n",
      "  [91a5bcdd] + Plots v1.2.2\n",
      "  [3cdcf5f2] + RecipesBase v1.0.1\n",
      "  [01d81517] + RecipesPipeline v0.1.7\n",
      "  [189a3867] + Reexport v0.2.0\n",
      "  [ae029012] + Requires v1.0.1\n",
      "  [992d4aef] + Showoff v0.3.1\n",
      "  [a2af1166] + SortingAlgorithms v0.3.1\n",
      "  [90137ffa] + StaticArrays v0.12.3\n",
      "  [2913bbd2] + StatsBase v0.33.0\n",
      "  [83775a58] + Zlib_jll v1.2.11+9\n",
      "  [0ac62f75] + libass_jll v0.14.0+2\n",
      "  [f638f0a6] + libfdk_aac_jll v0.1.6+2\n",
      "  [f27f6e37] + libvorbis_jll v1.3.6+4\n",
      "  [1270edf5] + x264_jll v2019.5.25+2\n",
      "  [dfaa095f] + x265_jll v3.0.0+1\n",
      "  [2a0f44e3] + Base64 \n",
      "  [ade2ca70] + Dates \n",
      "  [8bb1440f] + DelimitedFiles \n",
      "  [8ba89e20] + Distributed \n",
      "  [b77e0a4c] + InteractiveUtils \n",
      "  [76f85450] + LibGit2 \n",
      "  [8f399da3] + Libdl \n",
      "  [37e2e46d] + LinearAlgebra \n",
      "  [56ddb016] + Logging \n",
      "  [d6f4376e] + Markdown \n",
      "  [a63ad114] + Mmap \n",
      "  [44cfe95a] + Pkg \n",
      "  [de0858da] + Printf \n",
      "  [3fa0cd96] + REPL \n",
      "  [9a3f8284] + Random \n",
      "  [ea8e919c] + SHA \n",
      "  [9e88b42a] + Serialization \n",
      "  [6462fe0b] + Sockets \n",
      "  [2f01184e] + SparseArrays \n",
      "  [10745b16] + Statistics \n",
      "  [8dfed614] + Test \n",
      "  [cf7118a7] + UUIDs \n",
      "  [4ec0a83e] + Unicode \n",
      "  Building GR ───→ `~/.julia/packages/GR/cRdXQ/deps/build.log`\n",
      "  Building Plots → `~/.julia/packages/Plots/V8QVi/deps/build.log`\n",
      " Resolving package versions...\n",
      " Installed VersionParsing ─ v1.2.0\n",
      " Installed Conda ────────── v1.4.1\n",
      " Installed MacroTools ───── v0.5.5\n",
      " Installed LaTeXStrings ─── v1.1.0\n",
      " Installed PyCall ───────── v1.91.4\n",
      " Installed PyPlot ───────── v2.9.0\n",
      "  Updating `~/.julia/environments/v1.3/Project.toml`\n",
      "  [d330b81b] + PyPlot v2.9.0\n",
      "  Updating `~/.julia/environments/v1.3/Manifest.toml`\n",
      "  [8f4d0f93] + Conda v1.4.1\n",
      "  [b964fa9f] + LaTeXStrings v1.1.0\n",
      "  [1914dd2f] + MacroTools v0.5.5\n",
      "  [438e738f] + PyCall v1.91.4\n",
      "  [d330b81b] + PyPlot v2.9.0\n",
      "  [81def892] + VersionParsing v1.2.0\n",
      "  Building Conda ─→ `~/.julia/packages/Conda/3rPhK/deps/build.log`\n",
      "  Building PyCall → `~/.julia/packages/PyCall/zqDXB/deps/build.log`\n",
      " Resolving package versions...\n",
      " Installed MbedTLS_jll ───── v2.16.0+2\n",
      " Installed ZeroMQ_jll ────── v4.3.2+2\n",
      " Installed SoftGlobalScope ─ v1.0.10\n",
      " Installed ZMQ ───────────── v1.2.0\n",
      " Installed IJulia ────────── v1.21.2\n",
      " Installed MbedTLS ───────── v1.0.2\n",
      "  Updating `~/.julia/environments/v1.3/Project.toml`\n",
      "  [7073ff75] + IJulia v1.21.2\n",
      "  Updating `~/.julia/environments/v1.3/Manifest.toml`\n",
      "  [7073ff75] + IJulia v1.21.2\n",
      "  [739be429] + MbedTLS v1.0.2\n",
      "  [c8ffd9c3] + MbedTLS_jll v2.16.0+2\n",
      "  [b85f4697] + SoftGlobalScope v1.0.10\n",
      "  [c2297ded] + ZMQ v1.2.0\n",
      "  [8f1865be] + ZeroMQ_jll v4.3.2+2\n",
      "  [7b1f6079] + FileWatching \n",
      "  Building IJulia → `~/.julia/packages/IJulia/DrVMH/deps/build.log`\n",
      " Resolving package versions...\n",
      " Installed CompilerSupportLibraries_jll ─ v0.3.3+0\n",
      " Installed TimerOutputs ───────────────── v0.5.5\n",
      " Installed Cthulhu ────────────────────── v1.0.2\n",
      " Installed NNlib ──────────────────────── v0.6.6\n",
      " Installed AutoGrad ───────────────────── v1.2.1\n",
      " Installed GPUArrays ──────────────────── v3.2.0\n",
      " Installed CodecZlib ──────────────────── v0.7.0\n",
      " Installed CuArrays ───────────────────── v2.1.0\n",
      " Installed SpecialFunctions ───────────── v0.10.0\n",
      " Installed CUDAapi ────────────────────── v4.0.0\n",
      " Installed ExprTools ──────────────────── v0.1.1\n",
      " Installed CodeTracking ───────────────── v0.5.11\n",
      " Installed AbstractFFTs ───────────────── v0.5.0\n",
      " Installed CEnum ──────────────────────── v0.2.0\n",
      " Installed Adapt ──────────────────────── v1.0.1\n",
      " Installed Knet ───────────────────────── v1.3.5\n",
      " Installed TranscodingStreams ─────────── v0.9.5\n",
      " Installed LLVM ───────────────────────── v1.4.1\n",
      " Installed JLD2 ───────────────────────── v0.1.13\n",
      " Installed OpenSpecFun_jll ────────────── v0.5.3+3\n",
      " Installed CUDAdrv ────────────────────── v6.3.0\n",
      " Installed BinaryProvider ─────────────── v0.5.9\n",
      " Installed CUDAnative ─────────────────── v3.0.4\n",
      " Installed FileIO ─────────────────────── v1.3.0\n",
      "  Updating `~/.julia/environments/v1.3/Project.toml`\n",
      "  [1902f260] + Knet v1.3.5\n",
      "  Updating `~/.julia/environments/v1.3/Manifest.toml`\n",
      "  [621f4979] + AbstractFFTs v0.5.0\n",
      "  [79e6a3ab] + Adapt v1.0.1\n",
      "  [6710c13c] + AutoGrad v1.2.1\n",
      "  [b99e7846] + BinaryProvider v0.5.9\n",
      "  [fa961155] + CEnum v0.2.0\n",
      "  [3895d2a7] + CUDAapi v4.0.0\n",
      "  [c5f51814] + CUDAdrv v6.3.0\n",
      "  [be33ccc6] + CUDAnative v3.0.4\n",
      "  [da1fd8a2] + CodeTracking v0.5.11\n",
      "  [944b1d66] + CodecZlib v0.7.0\n",
      "  [e66e0078] + CompilerSupportLibraries_jll v0.3.3+0\n",
      "  [f68482b8] + Cthulhu v1.0.2\n",
      "  [3a865a2d] + CuArrays v2.1.0\n",
      "  [e2ba6199] + ExprTools v0.1.1\n",
      "  [5789e2e9] + FileIO v1.3.0\n",
      "  [0c68f7d7] + GPUArrays v3.2.0\n",
      "  [033835bb] + JLD2 v0.1.13\n",
      "  [1902f260] + Knet v1.3.5\n",
      "  [929cbde3] + LLVM v1.4.1\n",
      "  [872c559c] + NNlib v0.6.6\n",
      "  [efe28fd5] + OpenSpecFun_jll v0.5.3+3\n",
      "  [276daf66] + SpecialFunctions v0.10.0\n",
      "  [a759f4b9] + TimerOutputs v0.5.5\n",
      "  [3bb67fe8] + TranscodingStreams v0.9.5\n",
      "  Building NNlib → `~/.julia/packages/NNlib/FAI3o/deps/build.log`\n",
      "  Building Knet ─→ `~/.julia/packages/Knet/bTNMd/deps/build.log`\n",
      " Resolving package versions...\n",
      " Installed Libiconv_jll ────────────── v1.16.0+2\n",
      " Installed PaddedViews ─────────────── v0.5.5\n",
      " Installed Libuuid_jll ─────────────── v2.34.0+4\n",
      " Installed Gettext_jll ─────────────── v0.20.1+2\n",
      " Installed Xorg_xextproto_jll ──────── v7.3.0+1\n",
      " Installed libpng_jll ──────────────── v1.6.37+3\n",
      " Installed Xorg_libxcb_jll ─────────── v1.13.0+2\n",
      " Installed LZO_jll ─────────────────── v2.10.0+1\n",
      " Installed HarfBuzz_jll ────────────── v2.6.1+5\n",
      " Installed Xorg_util_macros_jll ────── v1.19.2+1\n",
      " Installed Libgpg_error_jll ────────── v1.36.0+1\n",
      " Installed XSLT_jll ────────────────── v1.1.33+2\n",
      " Installed Xorg_libXrender_jll ─────── v0.9.10+2\n",
      " Installed ImageCore ───────────────── v0.8.14\n",
      " Installed Xorg_libpthread_stubs_jll ─ v0.1.0+1\n",
      " Installed Glib_jll ────────────────── v2.59.0+2\n",
      " Installed MappedArrays ────────────── v0.2.2\n",
      " Installed Libmount_jll ────────────── v2.34.0+1\n",
      " Installed Xorg_xtrans_jll ─────────── v1.4.0+1\n",
      " Installed Luxor ───────────────────── v1.12.0\n",
      " Installed ImageMagick ─────────────── v0.7.5\n",
      " Installed Media ───────────────────── v0.5.0\n",
      " Installed MosaicViews ─────────────── v0.2.2\n",
      " Installed Graphics ────────────────── v1.0.2\n",
      " Installed Xorg_libXext_jll ────────── v1.3.4+2\n",
      " Installed Juno ────────────────────── v0.8.1\n",
      " Installed ColorVectorSpace ────────── v0.8.5\n",
      " Installed OffsetArrays ────────────── v1.0.4\n",
      " Installed Xorg_libXdmcp_jll ───────── v1.1.3+2\n",
      " Installed Libffi_jll ──────────────── v3.2.1+1\n",
      " Installed QuartzImageIO ───────────── v0.6.0\n",
      " Installed Graphite2_jll ───────────── v1.3.13+1\n",
      " Installed Expat_jll ───────────────── v2.2.7+1\n",
      " Installed XML2_jll ────────────────── v2.9.9+4\n",
      " Installed PCRE_jll ────────────────── v8.42.0+2\n",
      " Installed Fontconfig_jll ──────────── v2.13.1+11\n",
      " Installed Pixman_jll ──────────────── v0.38.4+2\n",
      " Installed Cairo_jll ───────────────── v1.16.0+4\n",
      " Installed Xorg_libXau_jll ─────────── v1.0.9+2\n",
      " Installed Pango_jll ───────────────── v1.42.4+8\n",
      " Installed Libgcrypt_jll ───────────── v1.8.5+1\n",
      " Installed Xorg_renderproto_jll ────── v0.11.1+1\n",
      " Installed Cairo ───────────────────── v1.0.3\n",
      " Installed Xorg_xcb_proto_jll ──────── v1.13.0+1\n",
      " Installed Xorg_libX11_jll ─────────── v1.6.9+2\n",
      " Installed Xorg_xproto_jll ─────────── v7.0.31+1\n",
      "  Updating `~/.julia/environments/v1.3/Project.toml`\n",
      "  [ae8d54c2] + Luxor v1.12.0\n",
      "  Updating `~/.julia/environments/v1.3/Manifest.toml`\n",
      "  [159f3aea] + Cairo v1.0.3\n",
      "  [83423d85] + Cairo_jll v1.16.0+4\n",
      "  [c3611d14] + ColorVectorSpace v0.8.5\n",
      "  [2e619515] + Expat_jll v2.2.7+1\n",
      "  [a3f928ae] + Fontconfig_jll v2.13.1+11\n",
      "  [78b55507] + Gettext_jll v0.20.1+2\n",
      "  [7746bdde] + Glib_jll v2.59.0+2\n",
      "  [a2bd30eb] + Graphics v1.0.2\n",
      "  [3b182d85] + Graphite2_jll v1.3.13+1\n",
      "  [2e76f6c2] + HarfBuzz_jll v2.6.1+5\n",
      "  [a09fc81d] + ImageCore v0.8.14\n",
      "  [6218d12a] + ImageMagick v0.7.5\n",
      "  [e5e0dc1b] + Juno v0.8.1\n",
      "  [dd4b983a] + LZO_jll v2.10.0+1\n",
      "  [e9f186c6] + Libffi_jll v3.2.1+1\n",
      "  [d4300ac3] + Libgcrypt_jll v1.8.5+1\n",
      "  [7add5ba3] + Libgpg_error_jll v1.36.0+1\n",
      "  [94ce4f54] + Libiconv_jll v1.16.0+2\n",
      "  [4b2f31a3] + Libmount_jll v2.34.0+1\n",
      "  [38a345b3] + Libuuid_jll v2.34.0+4\n",
      "  [ae8d54c2] + Luxor v1.12.0\n",
      "  [dbb5928d] + MappedArrays v0.2.2\n",
      "  [e89f7d12] + Media v0.5.0\n",
      "  [e94cdb99] + MosaicViews v0.2.2\n",
      "  [6fe1bfb0] + OffsetArrays v1.0.4\n",
      "  [2f80f16e] + PCRE_jll v8.42.0+2\n",
      "  [5432bcbf] + PaddedViews v0.5.5\n",
      "  [36c8627f] + Pango_jll v1.42.4+8\n",
      "  [30392449] + Pixman_jll v0.38.4+2\n",
      "  [dca85d43] + QuartzImageIO v0.6.0\n",
      "  [02c8fc9c] + XML2_jll v2.9.9+4\n",
      "  [aed1982a] + XSLT_jll v1.1.33+2\n",
      "  [4f6342f7] + Xorg_libX11_jll v1.6.9+2\n",
      "  [0c0b7dd1] + Xorg_libXau_jll v1.0.9+2\n",
      "  [a3789734] + Xorg_libXdmcp_jll v1.1.3+2\n",
      "  [1082639a] + Xorg_libXext_jll v1.3.4+2\n",
      "  [ea2f1a96] + Xorg_libXrender_jll v0.9.10+2\n",
      "  [14d82f49] + Xorg_libpthread_stubs_jll v0.1.0+1\n",
      "  [c7cfdc94] + Xorg_libxcb_jll v1.13.0+2\n",
      "  [21e99dc2] + Xorg_renderproto_jll v0.11.1+1\n",
      "  [7c09cfe3] + Xorg_util_macros_jll v1.19.2+1\n",
      "  [c2e9c405] + Xorg_xcb_proto_jll v1.13.0+1\n",
      "  [d13bc2ba] + Xorg_xextproto_jll v7.3.0+1\n",
      "  [46797783] + Xorg_xproto_jll v7.0.31+1\n",
      "  [c5fb5394] + Xorg_xtrans_jll v1.4.0+1\n",
      "  [b53b4c65] + libpng_jll v1.6.37+3\n",
      "  [9abbd945] + Profile \n",
      "  Building ImageMagick → `~/.julia/packages/ImageMagick/vMfoS/deps/build.log`\n",
      "  Building NNlib → `~/.julia/packages/NNlib/FAI3o/deps/build.log`\n",
      "  Building Knet ─→ `~/.julia/packages/Knet/bTNMd/deps/build.log`\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Installation cell\n",
    "%%shell\n",
    "if ! command -v julia 2>&1 > /dev/null\n",
    "then\n",
    "    wget 'https://julialang-s3.julialang.org/bin/linux/x64/1.3/julia-1.3.1-linux-x86_64.tar.gz' \\\n",
    "        -O /tmp/julia.tar.gz\n",
    "    tar -x -f /tmp/julia.tar.gz -C /usr/local --strip-components 1\n",
    "    rm /tmp/julia.tar.gz\n",
    "fi\n",
    "julia -e 'using Pkg; pkg\"add Plots; add PyPlot; add IJulia; add Knet; add Luxor\"'\n",
    "julia -e 'using Pkg; pkg\"build Knet;\"'\n",
    "julia -e 'precompile;'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qoUIoPfZQr0Q"
   },
   "source": [
    "<img src=\"http://drive.google.com/uc?export=view&id=1RJUAUMmViCsYSgyFj7oyqBu4c6AZMeFR\">\n",
    "\n",
    "T-Maze problem was designed to test Reinforcement Learning-LSTM's capability to bridge long time lags, without confounding the results by making the control task difficult in other ways [(Bakker, 2002)](http://papers.nips.cc/paper/1953-reinforcement-learning-with-long-short-term-memory.pdf]). However, we can also use this test-bed for supervised algorithms by exploiting the gold actions.\n",
    "\n",
    "In the T-Maze problem, the agent has four possible actions: move North, East, South, or West. The agent must learn to move from the starting position at the beginning of the corridor to the T-junction. There it must move either North or South to a changing goal position, which it cannot see. However, the location of the goal depends on a \"road sign\" the agent has seen at the starting position. At the starting position, the observation is either 011 (North) or 110 (South), in the corridor the observation is 101, and at the T-junction the observation is 010.\n",
    "\n",
    "In this assignment, you will complete lstm based architecture, train and test the model on different settings to inspect the learning curve and generalization power of the model. You will also explore the behavior of the model by visualizing hidden and cell vectors, and weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "yMlQv1ByQ-Xx",
    "outputId": "d8420913-bd4f-4d3d-8ad9-956764bd3251"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling Knet [1902f260-5fb4-5aff-8c31-6271790ab950]\n",
      "└ @ Base loading.jl:1273\n",
      "┌ Info: Precompiling Luxor [ae8d54c2-7ccd-5906-9d76-62fc9837b5bc]\n",
      "└ @ Base loading.jl:1273\n",
      "┌ Info: Precompiling Plots [91a5bcdd-55d7-5caf-9e0b-520d859cae80]\n",
      "└ @ Base loading.jl:1273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "draw (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Knet, Luxor, Plots, Random, Printf\n",
    "mutable struct TMaze\n",
    "    length::Int\n",
    "    goal::Int # 0 = North, 1 = South\n",
    "    agent_position::Tuple{Int,Int} # Agent's current position (x, y)\n",
    "end\n",
    "\n",
    "function get_state(maze::TMaze)\n",
    "    \"\"\"\n",
    "    Returns the current state\n",
    "    \"\"\"\n",
    "    \n",
    "    state = zeros(Float32, 3,)\n",
    "    \n",
    "    if maze.agent_position[1] == maze.length # At the T-junction\n",
    "        state[2] = 1.0\n",
    "    elseif maze.agent_position[1] == 0 # At the start position\n",
    "        if maze.goal == 0\n",
    "            state[2] = 1.0\n",
    "            state[3] = 1.0\n",
    "        else\n",
    "            state[1] = 1.0\n",
    "            state[2] = 1.0\n",
    "        end\n",
    "    else # In the corridor\n",
    "        state[1] = 1.0\n",
    "        state[3] = 1.0\n",
    "    end\n",
    "    return state\n",
    "end\n",
    "\n",
    "function step(maze::TMaze, action::Int)\n",
    "    \"\"\"\n",
    "    Gets action and plays one step. If the resulted state is the final state\n",
    "    then it checks whether it is the goal state or not. If it is a goal state\n",
    "    and the correct one it returns 1, if it is wrong it returns -1.\n",
    "    If the resulted state is not the final state, then it returns 0.\n",
    "    1 : North\n",
    "    2 : East\n",
    "    3 : South\n",
    "    4 : West\n",
    "    \"\"\"\n",
    "    p = maze.agent_position\n",
    "    res = 0\n",
    "    \n",
    "    if p[1] == maze.length && p[2] == 0\n",
    "        if action == 1\n",
    "            maze.agent_position = (p[1], min(-1, p[2]-1))\n",
    "            res = maze.goal == 0 ? 1 : -1\n",
    "        elseif action == 3\n",
    "            maze.agent_position = (p[1], min(1, p[2]+1))\n",
    "            res = maze.goal == 0 ? -1 : 1\n",
    "        elseif action == 4\n",
    "            maze.agent_position = (p[1]-1, 0)\n",
    "        end\n",
    "    elseif p[1] != maze.length && action == 2\n",
    "        maze.agent_position = (p[1]+1, 0)\n",
    "    elseif p[1] != maze.length && action == 4\n",
    "        maze.agent_position = (min(p[1]-1, 0), 0)\n",
    "    end\n",
    "    return res\n",
    "end\n",
    "\n",
    "function get_gold_actions(maze::TMaze)\n",
    "    \"\"\"\n",
    "    Returns a vector of integer for gold actions\n",
    "    \"\"\"\n",
    "    \n",
    "    gold_actions = ones(Int, maze.length) * 2\n",
    "    push!(gold_actions, maze.goal == 0 ? 1 : 3)\n",
    "    return gold_actions\n",
    "end\n",
    "\n",
    "function get_supervised_states(maze::TMaze)\n",
    "    \"\"\"\n",
    "    Returns the list of states for the gold actions.\n",
    "    The list includes the starting position, but does not include the final state.\n",
    "    \"\"\"\n",
    "    \n",
    "    p = maze.agent_position # store the agent position\n",
    "    \n",
    "    maze.agent_position = (0, 0)\n",
    "    \n",
    "    states = []\n",
    "    for action in get_gold_actions(maze)\n",
    "        push!(states, get_state(maze))\n",
    "        step(maze, action)\n",
    "    end\n",
    "    \n",
    "    maze.agent_position = p # reset\n",
    "    return states\n",
    "end\n",
    "\n",
    "function draw(maze::TMaze)\n",
    "    dim = 500 / (2 * (maze.length +1))\n",
    "    Drawing(500, round(Int, dim*3))\n",
    "    origin()\n",
    "    background(\"white\")\n",
    "    sethue(\"black\")\n",
    "    box.([O + (i*dim, 0) for i=0:maze.length], dim, dim, :stroke)\n",
    "    if maze.goal == 0\n",
    "        sethue(\"crimson\")\n",
    "        box.(O + (maze.length*dim, -dim), dim, dim, :fill)\n",
    "        sethue(\"black\")\n",
    "        box.(O + (maze.length*dim, dim), dim, dim, :stroke)\n",
    "        if maze.agent_position[1] == 0\n",
    "            Luxor.arrow(O + (0, -dim*0.65), Point(0, -dim*1.45))\n",
    "        end\n",
    "    else\n",
    "        sethue(\"crimson\")\n",
    "        box.(O + (maze.length*dim, dim), dim, dim, :fill)\n",
    "        sethue(\"black\")\n",
    "        box.(O + (maze.length*dim, -dim), dim, dim, :stroke)\n",
    "        if maze.agent_position[1] == 0\n",
    "            Luxor.arrow(O + (0, dim*0.65), Point(0, dim*1.45))\n",
    "        end\n",
    "    end\n",
    "    sethue(\"steelblue4\")\n",
    "    circle(O + (maze.agent_position[1]*dim,maze.agent_position[2]*dim), dim*0.45, :fill)\n",
    "    finish()\n",
    "    preview()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "opQgzdDwRDsa"
   },
   "outputs": [],
   "source": [
    "maze = TMaze(5,1,(0,0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "AEzZAQyDRFms",
    "outputId": "c7756111-f86a-4e38-d983-378d06458bd6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw(maze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "colab_type": "code",
    "id": "tDGQvEKyRIhH",
    "outputId": "b9736a70-8308-4a72-af3a-2cc8bae9a8e6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 3\n",
      "Result: 1"
     ]
    }
   ],
   "source": [
    "maze2 = TMaze(5,1,(0,0));\n",
    "draw(maze2)  \n",
    "sleep(1)\n",
    "\n",
    "#Let's animate\n",
    "for action in get_gold_actions(maze2)\n",
    "    res = step(maze2, action)\n",
    "    draw(maze2)    \n",
    "    print(\"Action: $action\\n\")\n",
    "    print(\"Result: $res\")\n",
    "    sleep(2) # sleep 1 second\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "qJdRkw27RIkD",
    "outputId": "a20dbe1e-ca12-49f4-89b7-43869b4cae19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Array{Int64,1}:\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 3"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gold_actions(maze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "zNsklvBtRJm1",
    "outputId": "8663b88c-d747-4b78-938a-ed0398d45f4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Array{Any,1}:\n",
       " Float32[1.0, 1.0, 0.0]\n",
       " Float32[1.0, 0.0, 1.0]\n",
       " Float32[1.0, 0.0, 1.0]\n",
       " Float32[1.0, 0.0, 1.0]\n",
       " Float32[1.0, 0.0, 1.0]\n",
       " Float32[0.0, 1.0, 0.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_supervised_states(maze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "O4cbUzYaRJo-",
    "outputId": "3e40f7e4-940a-4859-d042-345a71769157"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_all_data_up_to (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_all_data_up_to(N::Int)\n",
    "    \"\"\"\n",
    "    Generates a list of tuples, where each tuple contains supervised states\n",
    "    and gold actions for a specific configuration. There are 2N tuples in the\n",
    "    list.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for i=1:N\n",
    "        for goal in [0, 1]\n",
    "            maze = TMaze(i,goal,(0,0));\n",
    "            states = get_supervised_states(maze)\n",
    "            actions = get_gold_actions(maze)\n",
    "            push!(data, (states, actions))\n",
    "        end\n",
    "    end\n",
    "    return data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "K8uOLCKuRJr0",
    "outputId": "64213f31-0841-49ac-faeb-ed59668586d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Array{Any,1}:\n",
       " (Any[Float32[0.0, 1.0, 1.0], Float32[0.0, 1.0, 0.0]], [2, 1])                                                      \n",
       " (Any[Float32[1.0, 1.0, 0.0], Float32[0.0, 1.0, 0.0]], [2, 3])                                                      \n",
       " (Any[Float32[0.0, 1.0, 1.0], Float32[1.0, 0.0, 1.0], Float32[0.0, 1.0, 0.0]], [2, 2, 1])                           \n",
       " (Any[Float32[1.0, 1.0, 0.0], Float32[1.0, 0.0, 1.0], Float32[0.0, 1.0, 0.0]], [2, 2, 3])                           \n",
       " (Any[Float32[0.0, 1.0, 1.0], Float32[1.0, 0.0, 1.0], Float32[1.0, 0.0, 1.0], Float32[0.0, 1.0, 0.0]], [2, 2, 2, 1])\n",
       " (Any[Float32[1.0, 1.0, 0.0], Float32[1.0, 0.0, 1.0], Float32[1.0, 0.0, 1.0], Float32[0.0, 1.0, 0.0]], [2, 2, 2, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_all_data_up_to(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Km0GycZyRUA3"
   },
   "source": [
    "Unrolled lstm for the action prediction:\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"http://drive.google.com/uc?export=view&id=1icpMxPC3q6p-9ABWQfIg4R7dRQ6_MWar\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vz8Y17WDRZH5"
   },
   "source": [
    "## Problem 1. Implement the LSTM Agent\n",
    "You need to implement initweights function which takes hidden, world size and number of actions, and returns the whole model as `Array{Any}` julia data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LFZKlK7qRJvF"
   },
   "outputs": [],
   "source": [
    "# model definition\n",
    "\n",
    "struct Linear\n",
    "    w\n",
    "    b\n",
    "end\n",
    "\n",
    "# Initializer for a softmax classifier\n",
    "function Linear(num_inputs::Int, num_outputs::Int, init=gaussian)\n",
    "    # START YOUR ANSWER\n",
    "    \n",
    "    # END YOUR ANSWER\n",
    "end\n",
    "\n",
    "function (l::Linear)(x)\n",
    "    # START YOUR ANSWER\n",
    "    \n",
    "    # END YOUR ANSWER\n",
    "end\n",
    "\n",
    "struct LSTMNet\n",
    "    w\n",
    "    b\n",
    "end\n",
    "\n",
    "# Hint you mave take a look main function below to better understand its calling convention\n",
    "# Remember that, forget gate bias should be ones instead of zeros\n",
    "function LSTMNet(num_inputs::Int, hidden_size::Int, init=gaussian)\n",
    "    # START YOUR ANSWER\n",
    "    \n",
    "    # END YOUR ANSWER\n",
    "end\n",
    "\n",
    "# lstm procedure is given to you\n",
    "# weight * input .+ bias, concatenated weights for computational efficiency\n",
    "# You should use this function in your LSTM module call\n",
    "function lstm(weight, bias, hidden, cell, input)\n",
    "    gates   = weight * vcat(hidden,input) .+ bias\n",
    "    hsize   = size(hidden,1)\n",
    "    forget  = sigm.(gates[1:hsize,:])\n",
    "    ingate  = sigm.(gates[1+hsize:2hsize,:])\n",
    "    outgate = sigm.(gates[1+2hsize:3hsize,:])\n",
    "    change  = tanh.(gates[1+3hsize:end,:])\n",
    "    cell    = cell .* forget + ingate .* change\n",
    "    hidden  = outgate .* tanh.(cell)\n",
    "    return (hidden, cell)\n",
    "end\n",
    "\n",
    "function (l::LSTMNet)(x, prev_hidden, prev_cell)\n",
    "    # START YOUR ANSWER\n",
    "    \n",
    "    # END YOUR ANSWER\n",
    "end\n",
    "\n",
    "mutable struct LSTMAgent\n",
    "    lstm::LSTMNet # a lstm network\n",
    "    linear::Linear # a linear layer on top of the lstm network\n",
    "    state # Array{Any}(undef, 2) for hidden and cell states\n",
    "end\n",
    "\n",
    "function LSTMAgent(hidden_size::Int, world_dim::Int=3, num_actions::Int=4)\n",
    "    # START YOUR ANSWER\n",
    "    \n",
    "    # END YOUR ANSWER\n",
    "end\n",
    "\n",
    "# resets the hidden and cell states\n",
    "function reset!(model::LSTMAgent)\n",
    "    # START YOUR ANSWER\n",
    "    \n",
    "    # END YOUR ANSWER\n",
    "end\n",
    "\n",
    "# before calling the model you should reset the hidden and cell states\n",
    "# model gets world state(s) and applies the lstm function to each state in the world_states\n",
    "# and predicts a score vector for actions.\n",
    "function (model::LSTMAgent)(world_states)\n",
    "    scores = []\n",
    "    # START YOUR ANSWER\n",
    "    \n",
    "    # END YOUR ANSWER\n",
    "    return scores\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eHeApZNBRfnD"
   },
   "source": [
    "## Problem 2. Implement Loss function\n",
    "That function basically takes the predictions and returns the negative log-likelihood of these predictions as loss.\n",
    "Hint: You may have a look Knet's ```nll``` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_OsjWx9vRIm3",
    "outputId": "a2a918e6-0a9f-4b8d-8b08-d716a5f84e74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our loss function\n",
    "# hint: use nll function (type @doc nll in an another cell)\n",
    "function loss(model, world_states, gold_actions)\n",
    "    total = 0.0\n",
    "    scores = model(world_states)\n",
    "    \n",
    "    # START ANSWER\n",
    "    \n",
    "    # END ANSWER\n",
    "    lossval = total/length(gold_actions)\n",
    "    return lossval\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "AyYpRITpRiSo",
    "outputId": "01e0d543-76f7-4cf9-adc5-295ec68b7713"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train! (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train!(model, world_states, gold_actions)\n",
    "    L = @diff loss(model, world_states, gold_actions)\n",
    "    for p in params(model)\n",
    "        g = grad(L, p)\n",
    "        update!(value(p), g, p.opt)\n",
    "    end\n",
    "    return value(L)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "87TbqfO-Rk6c"
   },
   "source": [
    "## Problem 3. Implement Accuracy function\n",
    "Accuracy function checks each predicted action for a path and counts correct if all predictions are correct for a path. This function does not calculate the mean accuracy for the data, instead it returns a list storing accuracy of each path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "HYKrPDSNRiVh",
    "outputId": "69eaae9e-f8c0-4fc7-ceec-71edc7d2792b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path_accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# possible helpful procedures: argmax, vec\n",
    "function path_accuracy(model, data)\n",
    "    accuracies = []\n",
    "    for (world_states, gold_actions) in data\n",
    "        ncorrect = 0\n",
    "        reset!(model)\n",
    "        scores = model(world_states)\n",
    "        #ncorrect must be equal to the path length (i.e. length of the gold actions)\n",
    "        \n",
    "        # START ANSWER\n",
    "        \n",
    "        # END ANSWER\n",
    "        \n",
    "        push!(accuracies, ncorrect == length(gold_actions) ? 1.0 : 0.0)\n",
    "    end\n",
    "\n",
    "    return accuracies\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5Y9eUHaVRiYz",
    "outputId": "afe52660-9775-4bf0-88a4-3c67307bfdfd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_until_all_success (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train_until_all_success(model, data; maxe=50000)\n",
    "    \"\"\"\n",
    "    Gets model parameters w, initial states s, optimizers opt and data.\n",
    "    It trains the model untill the accuracy on the data reach to 1.0.\n",
    "    \"\"\"\n",
    "    experiment = []\n",
    "    for i=1:maxe\n",
    "        world_states, gold_actions = rand(data) #sample data\n",
    "        reset!(model)\n",
    "        train!(model, world_states, gold_actions)\n",
    "        \n",
    "        accuracies = path_accuracy(model, data)\n",
    "        total = sum(accuracies)/length(accuracies)\n",
    "        push!(experiment, total)\n",
    "        print(\"\\r Number of Instances: $i Acc: $(@sprintf(\"%.3f\", total))\")\n",
    "        if total == 1.0\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    return experiment\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6U7IuKSpRrDC"
   },
   "outputs": [],
   "source": [
    "data = get_all_data_up_to(10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "colab_type": "code",
    "id": "1IEOExdFRs3f",
    "outputId": "723d4494-aa54-45b4-e9e6-f02e31ab2c26"
   },
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching reset!(::Nothing)\nClosest candidates are:\n  reset!(!Matched::LSTMAgent) at In[9]:71",
      "",
      "Stacktrace:",
      " [1] #train_until_all_success#7(::Int64, ::typeof(train_until_all_success), ::Nothing, ::Array{Any,1}) at ./In[13]:9",
      " [2] (::var\"#kw##train_until_all_success\")(::NamedTuple{(:maxe,),Tuple{Int64}}, ::typeof(train_until_all_success), ::Nothing, ::Array{Any,1}) at ./none:0",
      " [3] top-level scope at In[15]:11"
     ]
    }
   ],
   "source": [
    "Knet.seed!(123456)\n",
    "\n",
    "HIDDEN = 4\n",
    "\n",
    "model_4 = LSTMAgent(HIDDEN)\n",
    "for p in params(model_4)\n",
    "    p.opt = Adam()\n",
    "end\n",
    "\n",
    "Random.seed!(123456)\n",
    "hidden_4 = train_until_all_success(model_4, data; maxe=100000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "colab_type": "code",
    "id": "IZO9KCrJRs6K",
    "outputId": "1ab30df8-1db0-4be3-da5b-57120bee7a08"
   },
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching reset!(::Nothing)\nClosest candidates are:\n  reset!(!Matched::LSTMAgent) at In[9]:71",
      "",
      "Stacktrace:",
      " [1] #train_until_all_success#7(::Int64, ::typeof(train_until_all_success), ::Nothing, ::Array{Any,1}) at ./In[13]:9",
      " [2] (::var\"#kw##train_until_all_success\")(::NamedTuple{(:maxe,),Tuple{Int64}}, ::typeof(train_until_all_success), ::Nothing, ::Array{Any,1}) at ./none:0",
      " [3] top-level scope at In[16]:11"
     ]
    }
   ],
   "source": [
    "Knet.seed!(123456)\n",
    "\n",
    "HIDDEN = 8\n",
    "\n",
    "model_8 = LSTMAgent(HIDDEN)\n",
    "for p in params(model_8)\n",
    "    p.opt = Adam()\n",
    "end\n",
    "\n",
    "Random.seed!(123456)\n",
    "hidden_8 = train_until_all_success(model_8, data; maxe=100000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "colab_type": "code",
    "id": "-jiYOGIIRs9A",
    "outputId": "fdbf146b-945a-45ed-c534-990cc23070c5"
   },
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching reset!(::Nothing)\nClosest candidates are:\n  reset!(!Matched::LSTMAgent) at In[9]:71",
      "",
      "Stacktrace:",
      " [1] #train_until_all_success#7(::Int64, ::typeof(train_until_all_success), ::Nothing, ::Array{Any,1}) at ./In[13]:9",
      " [2] (::var\"#kw##train_until_all_success\")(::NamedTuple{(:maxe,),Tuple{Int64}}, ::typeof(train_until_all_success), ::Nothing, ::Array{Any,1}) at ./none:0",
      " [3] top-level scope at In[17]:11"
     ]
    }
   ],
   "source": [
    "Knet.seed!(123456)\n",
    "\n",
    "HIDDEN = 16\n",
    "\n",
    "model_16 = LSTMAgent(HIDDEN)\n",
    "for p in params(model_16)\n",
    "    p.opt = Adam()\n",
    "end\n",
    "\n",
    "Random.seed!(123456)\n",
    "hidden_16 = train_until_all_success(model_16, data; maxe=100000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "id": "_P-KTZItRs_z",
    "outputId": "bcbc7bc6-a25e-479b-cb8e-d15bdcf59c06"
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "UndefVarError: hidden_4 not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[18]:1"
     ]
    }
   ],
   "source": [
    "plot([1:length(hidden_4), 1:length(hidden_8), 1:length(hidden_16)],\n",
    "    [hidden_4, hidden_8, hidden_16],\n",
    "    label=[\"hidden_4\" \"hidden_8\" \"hidden_16\"],\n",
    "    xlabel=\"Number of instances\", ylabel=\"Accuracy\", title=\"Hidden size comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dG6r3sePRtCq"
   },
   "outputs": [],
   "source": [
    "limit = 50\n",
    "test_data = get_all_data_up_to(limit);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "colab_type": "code",
    "id": "-BMVEfygR1N1",
    "outputId": "752ab554-cc07-4c87-be11-cbb4a22806d2"
   },
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching reset!(::Nothing)\nClosest candidates are:\n  reset!(!Matched::LSTMAgent) at In[9]:71",
      "",
      "Stacktrace:",
      " [1] path_accuracy(::Nothing, ::Array{Any,1}) at ./In[12]:5",
      " [2] top-level scope at In[20]:1"
     ]
    }
   ],
   "source": [
    "accuracies = path_accuracy(model_4, test_data)\n",
    "N_4 = map(x->sum(accuracies[(x-1)*2+1:x*2])/2, 1:limit);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "colab_type": "code",
    "id": "jDufu976R1Qd",
    "outputId": "436894bf-764b-4642-a4e8-9eac1d453427"
   },
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching reset!(::Nothing)\nClosest candidates are:\n  reset!(!Matched::LSTMAgent) at In[9]:71",
      "",
      "Stacktrace:",
      " [1] path_accuracy(::Nothing, ::Array{Any,1}) at ./In[12]:5",
      " [2] top-level scope at In[21]:1"
     ]
    }
   ],
   "source": [
    "accuracies = path_accuracy(model_8, test_data)\n",
    "N_8 = map(x->sum(accuracies[(x-1)*2+1:x*2])/2, 1:limit);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "colab_type": "code",
    "id": "Wk4QdIn4R1TD",
    "outputId": "de0e0c5f-ea56-411e-fcf5-59945c6392c4"
   },
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching reset!(::Nothing)\nClosest candidates are:\n  reset!(!Matched::LSTMAgent) at In[9]:71",
      "",
      "Stacktrace:",
      " [1] path_accuracy(::Nothing, ::Array{Any,1}) at ./In[12]:5",
      " [2] top-level scope at In[22]:1"
     ]
    }
   ],
   "source": [
    "accuracies = path_accuracy(model_16, test_data)\n",
    "N_16 = map(x->sum(accuracies[(x-1)*2+1:x*2])/2, 1:limit);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "id": "Ce1lUPZvR1WK",
    "outputId": "7a1f4144-6d9d-4714-b570-19af97a8dba0"
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "UndefVarError: N_4 not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[23]:1"
     ]
    }
   ],
   "source": [
    "plot([N_4 N_8 N_16], linetype=:scatter, m=[:circle :cross :star5],\n",
    "    label=[\"hidden_4\" \"hidden_8\" \"hidden_16\"],\n",
    "    xlabel=\"Corridor Length\", ylabel=\"Accuracy\", title=\"Generalization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "at4U1ENsR9Xi"
   },
   "source": [
    "hidden_4 and hidden_8 models can only handle up to corridor length equals to 15. However, hidden_16 is able to solve the task. Let's inspect the behaviour of this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4qWgVe5YSAMn"
   },
   "source": [
    "## Problem 4. Implement Play function\n",
    "`play` function gets a maze, trained model parameters w and initial states s. It takes action using the model until either the agent reaches the final state or exceeds the maximum action limit. The function returns the actions taken, hidden and cell states of the lstm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "OVC4zRhtSC7z",
    "outputId": "ef611ec9-3c53-42d4-d08f-cd3d11815e7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "play (generic function with 1 method)"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function play(maze, model; max_actions=20)\n",
    "    res = 0\n",
    "    action_count = 0\n",
    "    hiddens = []\n",
    "    cells = []\n",
    "    actions = []\n",
    "    draw(maze)\n",
    "    reset!(model)\n",
    "    while !(res != 0 || action_count >= max_actions)\n",
    "        sleep(1) # sleep 1 second\n",
    "        x = get_state(maze) # get state\n",
    "        # START ANSWER\n",
    "        \n",
    "        # END ANSWER\n",
    "        \n",
    "        res = step(maze, action) # prediction from the model\n",
    "        draw(maze)\n",
    "        action_count += 1\n",
    "    end\n",
    "    \n",
    "    return actions, hiddens, cells\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "colab_type": "code",
    "id": "TYoHa06ySE4x",
    "outputId": "9f5ea5d7-6d83-497f-db7f-f7e18b0634fe"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAB9CAIAAADbfAZ5AAAABmJLR0QA/wD/AP+gvaeTAAAIaklEQVR4nO3dXVBU5xnA8XdXYGXRNTEYHWW1CX6ysWxiJUo1KKm2QCdmyGimTjsZ7UXbm36M7fSuQtuLTpkynUzU0ZZYsLTGTgDTSYwbq6DR+lEFdF2swLQWxA80dhdZ1IXdXjB1MrZO63LOezzP/n8XjIOc93lnB/9zPGc5OBKJhAIA/IdPfv72raqdVk33HqnLmP9M0oc7DdwKAOAxQdyRKoLBYDAYtHoXgCbEHali69at27Zts3oXgCbEHSlhYGCgvr6+rq4uEolYvRdAB+KOlFBbWxuJRG7fvr1r1y6r9wLoQNyRErZv3z76hy1btvAOMaQC4g75mpub799K7ejoOHz4sLX7ATQg7pDvgfuo3FZFKiDuEO7q1auNjY2f/kxDQ0NfX59V+wH0IO4QbseOHbFY7NOficViNTU1Vu0H0CPN6g0A5lq+fPmePXuUUseOHVNKFRYWKqWys7Mt3hZgMuIO4VauXDn6h/Pnzyul1q5da+l2AE24LAMAAhF3ABCIuAOAQMQdAAQi7gAgEHEHAIGIOwAIRNwBQCDiDgACEXcAEIi4A4BAxB0ABCLuACAQcQcAgYg7AAhE3AFAIOIOAAIRdwAQiLgDgEDEHQAEIu4AIBBxBwCB0qzeAKBJWVmZ1VsA9CHuSBWLFy+2eguAPlyWAQCBiDsACETcAUAgrrnDNgKBQDgctmT00NBQW1ub2+3Oz8/XP723t7enp8fr9ebk5Oif3t7eHo1G/X5/Zmam5tGWv+zT9h8v0D/43/bv3180fb3H40nucEcikTB2Q4BJfD5fKBSyehdIISWu7LKMbKum/3TwbwfOnvb5fMkdzpk7bGb16tVJn8sk7cqVK0ePHnU6neXl5ZpHK6VaWlr6+/unTJlSVFSkf3pDQ0M8Hi8sLJw+fbrm0Za/7Pv6+//icVjysgcCgUj87piWSAA2kZeXp5QKBoOPemBkcKiz5/rZrstnuy539lyPDA496gp79+5VSrlcrkc90BCjcSkqKrJkusvlUko1NTXpH53KL3vS3+33ceYOmW6GBw+evniy49K57r5bA9EH/nayx70wd3rBglnFi+ZN9rgt2SFgKuIOaUJ/v1r7wYkj7d0j8fjDvuaTSLSltaultat696GX/LlvlLy44DPTdG4SMBtxhxw3/nn7l3uaPzp14f8/ZCQeP3Sm89CZztUF87+zbmX2pCzztgfoRNwhxJH27h/v3BcZvJPc4YGTF06ELm3eUPL5zz5r7MYAS/BDTJDgnT+d+cGWxqTLPip8e2jTWw27Pjxp1K4AC3HmDtv79R+P/eq9Y4YslUiot949HBuJbyxbYsiCgFU4c4e9Nba0G1X2+7Y3ffzex+eMXRPQjLjDxi5cula9+6AZK1fVH/jrP66ZsTKgB3GHXY3E4z/5zYf3hkfMWPze8Ejl2/uGRx76ZkrgMUfcYVe7D5zp6u03b/3uyzfebW4zb33AVMQdtnQvNvy7wCmzp9TuO3E3Nmz2FMAMxB22tO94x43woNlTboYHPzr5CD8SBTw+iDts6YM/n9cz6H1dgwBjEXfYT2Twztmuy3pmtXX2DkTH9uRVwArEHfbTerE3ruuXzMTjibbOXj2zAAMRd9iPqW+SsXwcYAjiDvvp6b+lddx1reMAQxB32M/AoNaL4GN8HhlgCeIO+7kbi+kcd+ee1nGAIYg77MeVnq5z3PgMreMAQxB32M/ELJfOcZ6s8TrHAYYg7rAf79NP6hw3c6rWcYAhiDvsZ07OFJ3jcmdoHQcYgrjDfp6f63U6HXpmOZ0O/5wcPbMAAxF32M9Etyt/9gw9s16Y653o1nqJHzAEcYctlS316RlUsjRPzyDAWMQdtvTFFxdkT8oye8pTk7JWLZ5v9hTADMQdtpSRnva1LxWYPWVD6RJXeprZUwAzEHfY1dri5+d4TXwfS+6M7PIV+eatD5iKuMOuxjmdFRtLTTqzzkhP27yxdJyTfyCwK753YWOzc6Z8f/3Lhi/rcKgffvUL82Y+bfjKgDbEHfb2yrKF33h1mbFrfvPVZV8ufM7YNQHNuFkE29tYtmR8Rtqbf2ge+29ncjoc33195esvv2DEvgArceYOCdav+tyb31s72eMeyyJPTMj8xbfLKTtkIO4QomDBrN/+6I2SJXmOR38wgcOhSpf6fl+5ofC5Z0zYGmABLstAjqcmZVV8vfQrqxbtfP/Ekfau4ZH4/zwkbZzzJf/sDWVL5nq5fQpRiDukmTdz6s++9cqtgejB0xdPdVw61913Izz4wNdkT8pamDujIG9W8aK5T0zItGSfgKmIO2R6cqL7tRX+11b4lVID0bvXbw0M3Y0ppTJd6VMnT5yQybPAIBxxh81s2rTJ4/FoHtrX16eUisVi69at0zxaKRUKhUY/WjI9Fosppaqqqurr6zWPtvZlb21tVUodP37c6/Xqn37t2rXRjz5fks/IcyTG/vYxQAufzzeaOSBFNDU1rVmzJrljOXOHbVRXV4fDYUtGDw0NtbW1ud3u/HwLnjbT09PT29ubk5NjySlke3t7NBr1+/2ZmbpvTlj7stfU1AQCgfz8/OLiYv3T6+rqbt68OW3atKRX4MwdAP6LioqKysrKzZs3V1RU6J8++v/UYDCY9GUZ3ucOAAIRdwAQiLgDgEDEHQAEIu4AIBBxBwCBiDsACETcAUAg4g4AAhF3ABCIuAOAQMQdAAQi7gAgEHEHAIGIOwAIRNwBQCDiDgACEXcAEIi4A4BAxB0ABCLuACAQcQcAgYg7AAhE3AFAIOIOAAIRdwAQiLgDgEDEHQAEIu4AIBBxBwCBiDsACETcAUAg4g4AAhF3ABCIuAOAQMQdAAQi7gAgEHEHAIGIOwA8VGVlpcMKoVBojDv/F2zx1DrXDHU0AAAAAElFTkSuQmCC"
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "ename": "MethodError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching reset!(::Nothing)\nClosest candidates are:\n  reset!(!Matched::LSTMAgent) at In[9]:71",
      "",
      "Stacktrace:",
      " [1] #play#8(::Int64, ::typeof(play), ::TMaze, ::Nothing) at ./In[24]:8",
      " [2] play(::TMaze, ::Nothing) at ./In[24]:2",
      " [3] top-level scope at In[25]:2"
     ]
    }
   ],
   "source": [
    "maze = TMaze(5, 0, (0, 0))\n",
    "actions_0, hiddens_0, cells_0 = play(maze, model_16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "id": "SdXFqjpwSIkE",
    "outputId": "2db97b86-26f7-496e-999d-5e49a8bbc246"
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "UndefVarError: hiddens_0 not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[26]:3"
     ]
    }
   ],
   "source": [
    "xs = [string(\"state\", i) for i = 1:maze.length+1]\n",
    "ys = [string(\"unit\", i) for i = 1:16]\n",
    "heatmap(xs, ys, hcat(hiddens_0...), title=\"Hidden states for a maze(length=5) and the goal is north\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "id": "fcqNMdLSSImg",
    "outputId": "ecdc5166-79f5-499c-b3a5-72d3241e5314"
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "UndefVarError: cells_0 not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[27]:3"
     ]
    }
   ],
   "source": [
    "xs = [string(\"state\", i) for i = 1:maze.length+1]\n",
    "ys = [string(\"unit\", i) for i = 1:16]\n",
    "heatmap(xs, ys, hcat(cells_0...), title=\"Cell states for a maze(length=5) and the goal is north\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "colab_type": "code",
    "id": "LFqK9ndWSIpa",
    "outputId": "1e896de9-114b-4729-9eab-69f00ad5be50"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "ename": "MethodError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching reset!(::Nothing)\nClosest candidates are:\n  reset!(!Matched::LSTMAgent) at In[9]:71",
      "",
      "Stacktrace:",
      " [1] #play#8(::Int64, ::typeof(play), ::TMaze, ::Nothing) at ./In[24]:8",
      " [2] play(::TMaze, ::Nothing) at ./In[24]:2",
      " [3] top-level scope at In[28]:2"
     ]
    }
   ],
   "source": [
    "maze = TMaze(5, 1, (0, 0))\n",
    "actions_1, hiddens_1, cells_1 = play(maze, model_16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "id": "8_tmEkwySIr7",
    "outputId": "82bcb857-5859-410a-a265-33a02a0bba21"
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "UndefVarError: hiddens_1 not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[29]:3"
     ]
    }
   ],
   "source": [
    "xs = [string(\"state\", i) for i = 1:maze.length+1]\n",
    "ys = [string(\"unit\", i) for i = 1:16]\n",
    "heatmap(xs, ys, hcat(hiddens_1...), title=\"Hidden states for a maze(length=5) and the goal is south\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "id": "vJaaoKmrSIuu",
    "outputId": "020a0c63-1100-4205-ce98-a71eb566439b"
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "UndefVarError: cells_1 not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[30]:3"
     ]
    }
   ],
   "source": [
    "xs = [string(\"state\", i) for i = 1:maze.length+1]\n",
    "ys = [string(\"unit\", i) for i = 1:16]\n",
    "heatmap(xs, ys, hcat(cells_1...), title=\"Cell states for a maze(length=5) and the goal is south\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PyCga-U3SRA7"
   },
   "source": [
    "Until the t-junction, the model preserves the hidden state and at the t-junction it switches hidden state for the final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KVCzG_5KSTJH"
   },
   "source": [
    "## Problem 5. Weight Visualization\n",
    "Complete following code snippets to visualize weights used for different components in the model. Since each gate has different purpose, inspect each weight and bias vector individually. At the end of the section, give your explanation about obtained results. Use the weights model_16 for hidden size equals to 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "colab_type": "code",
    "id": "3rGDXLoNSIxv",
    "outputId": "15970983-3433-4fae-ef06-1d737a604ec5"
   },
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "Cannot convert String to series data for plotting",
      "",
      "Stacktrace:",
      " [1] error(::String) at ./error.jl:33",
      " [2] _prepare_series_data(::String) at /root/.julia/packages/RecipesPipeline/2pkja/src/series.jl:8",
      " [3] _series_data_vector(::String, ::Dict{Symbol,Any}) at /root/.julia/packages/RecipesPipeline/2pkja/src/series.jl:27",
      " [4] macro expansion at /root/.julia/packages/RecipesPipeline/2pkja/src/series.jl:140 [inlined]",
      " [5] apply_recipe(::Dict{Symbol,Any}, ::Type{RecipesPipeline.SliceIt}, ::Array{String,1}, ::Array{String,1}, ::String) at /root/.julia/packages/RecipesBase/jcXIg/src/RecipesBase.jl:281",
      " [6] _process_userrecipes!(::Plots.Plot{Plots.GRBackend}, ::Dict{Symbol,Any}, ::Tuple{Array{String,1},Array{String,1},String}) at /root/.julia/packages/RecipesPipeline/2pkja/src/user_recipe.jl:35",
      " [7] recipe_pipeline!(::Plots.Plot{Plots.GRBackend}, ::Dict{Symbol,Any}, ::Tuple{Array{String,1},Array{String,1},String}) at /root/.julia/packages/RecipesPipeline/2pkja/src/RecipesPipeline.jl:68",
      " [8] _plot!(::Plots.Plot{Plots.GRBackend}, ::Dict{Symbol,Any}, ::Tuple{Array{String,1},Array{String,1},String}) at /root/.julia/packages/Plots/V8QVi/src/plot.jl:167",
      " [9] #plot#124(::Base.Iterators.Pairs{Symbol,Any,Tuple{Symbol,Symbol},NamedTuple{(:title, :seriestype),Tuple{String,Symbol}}}, ::typeof(plot), ::Array{String,1}, ::Vararg{Any,N} where N) at /root/.julia/packages/Plots/V8QVi/src/plot.jl:57",
      " [10] (::RecipesBase.var\"#kw##plot\")(::NamedTuple{(:title, :seriestype),Tuple{String,Symbol}}, ::typeof(plot), ::Array{String,1}, ::Array{String,1}, ::Vararg{Any,N} where N) at ./none:0",
      " [11] #heatmap#367(::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:title,),Tuple{String}}}, ::typeof(heatmap), ::Array{String,1}, ::Vararg{Any,N} where N) at /root/.julia/packages/RecipesBase/jcXIg/src/RecipesBase.jl:402",
      " [12] (::Plots.var\"#kw##heatmap\")(::NamedTuple{(:title,),Tuple{String}}, ::typeof(heatmap), ::Array{String,1}, ::Vararg{Any,N} where N) at ./none:0",
      " [13] top-level scope at In[31]:3"
     ]
    }
   ],
   "source": [
    "xs = [string(\"h\", i) for i = 1:16]\n",
    "ys = [string(\"w\", i) for i = 1:16]\n",
    "heatmap(xs, ys, \"YOUR CODE HERE\", title=\"Forget gate weight used in W_forget * prev_hidden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "colab_type": "code",
    "id": "Nz2sjZ1VSW86",
    "outputId": "668c14e9-b101-4226-c656-14c19b1e13bb"
   },
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "Cannot convert String to series data for plotting",
      "",
      "Stacktrace:",
      " [1] error(::String) at ./error.jl:33",
      " [2] _prepare_series_data(::String) at /root/.julia/packages/RecipesPipeline/2pkja/src/series.jl:8",
      " [3] _series_data_vector(::String, ::Dict{Symbol,Any}) at /root/.julia/packages/RecipesPipeline/2pkja/src/series.jl:27",
      " [4] macro expansion at /root/.julia/packages/RecipesPipeline/2pkja/src/series.jl:140 [inlined]",
      " [5] apply_recipe(::Dict{Symbol,Any}, ::Type{RecipesPipeline.SliceIt}, ::Array{String,1}, ::Array{String,1}, ::String) at /root/.julia/packages/RecipesBase/jcXIg/src/RecipesBase.jl:281",
      " [6] _process_userrecipes!(::Plots.Plot{Plots.GRBackend}, ::Dict{Symbol,Any}, ::Tuple{Array{String,1},Array{String,1},String}) at /root/.julia/packages/RecipesPipeline/2pkja/src/user_recipe.jl:35",
      " [7] recipe_pipeline!(::Plots.Plot{Plots.GRBackend}, ::Dict{Symbol,Any}, ::Tuple{Array{String,1},Array{String,1},String}) at /root/.julia/packages/RecipesPipeline/2pkja/src/RecipesPipeline.jl:68",
      " [8] _plot!(::Plots.Plot{Plots.GRBackend}, ::Dict{Symbol,Any}, ::Tuple{Array{String,1},Array{String,1},String}) at /root/.julia/packages/Plots/V8QVi/src/plot.jl:167",
      " [9] #plot#124(::Base.Iterators.Pairs{Symbol,Any,Tuple{Symbol,Symbol},NamedTuple{(:title, :seriestype),Tuple{String,Symbol}}}, ::typeof(plot), ::Array{String,1}, ::Vararg{Any,N} where N) at /root/.julia/packages/Plots/V8QVi/src/plot.jl:57",
      " [10] (::RecipesBase.var\"#kw##plot\")(::NamedTuple{(:title, :seriestype),Tuple{String,Symbol}}, ::typeof(plot), ::Array{String,1}, ::Array{String,1}, ::Vararg{Any,N} where N) at ./none:0",
      " [11] #heatmap#367(::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:title,),Tuple{String}}}, ::typeof(heatmap), ::Array{String,1}, ::Vararg{Any,N} where N) at /root/.julia/packages/RecipesBase/jcXIg/src/RecipesBase.jl:402",
      " [12] (::Plots.var\"#kw##heatmap\")(::NamedTuple{(:title,),Tuple{String}}, ::typeof(heatmap), ::Array{String,1}, ::Vararg{Any,N} where N) at ./none:0",
      " [13] top-level scope at In[32]:3"
     ]
    }
   ],
   "source": [
    "xs = [string(\"x\", i) for i = 1:3]\n",
    "ys = [string(\"w\", i) for i = 1:16]\n",
    "heatmap(xs, ys, \"YOUR CODE HERE\", title=\"Forget gate weight used in W_forget * x_t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "colab_type": "code",
    "id": "8a6qGn3MSW_R",
    "outputId": "29715029-27b6-48fd-c268-47f63481506b"
   },
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "Cannot convert String to series data for plotting",
      "",
      "Stacktrace:",
      " [1] error(::String) at ./error.jl:33",
      " [2] _prepare_series_data(::String) at /root/.julia/packages/RecipesPipeline/2pkja/src/series.jl:8",
      " [3] _series_data_vector(::String, ::Dict{Symbol,Any}) at /root/.julia/packages/RecipesPipeline/2pkja/src/series.jl:27",
      " [4] macro expansion at /root/.julia/packages/RecipesPipeline/2pkja/src/series.jl:140 [inlined]",
      " [5] apply_recipe(::Dict{Symbol,Any}, ::Type{RecipesPipeline.SliceIt}, ::Array{String,1}, ::Array{String,1}, ::String) at /root/.julia/packages/RecipesBase/jcXIg/src/RecipesBase.jl:281",
      " [6] _process_userrecipes!(::Plots.Plot{Plots.GRBackend}, ::Dict{Symbol,Any}, ::Tuple{Array{String,1},Array{String,1},String}) at /root/.julia/packages/RecipesPipeline/2pkja/src/user_recipe.jl:35",
      " [7] recipe_pipeline!(::Plots.Plot{Plots.GRBackend}, ::Dict{Symbol,Any}, ::Tuple{Array{String,1},Array{String,1},String}) at /root/.julia/packages/RecipesPipeline/2pkja/src/RecipesPipeline.jl:68",
      " [8] _plot!(::Plots.Plot{Plots.GRBackend}, ::Dict{Symbol,Any}, ::Tuple{Array{String,1},Array{String,1},String}) at /root/.julia/packages/Plots/V8QVi/src/plot.jl:167",
      " [9] #plot#124(::Base.Iterators.Pairs{Symbol,Any,Tuple{Symbol,Symbol},NamedTuple{(:title, :seriestype),Tuple{String,Symbol}}}, ::typeof(plot), ::Array{String,1}, ::Vararg{Any,N} where N) at /root/.julia/packages/Plots/V8QVi/src/plot.jl:57",
      " [10] (::RecipesBase.var\"#kw##plot\")(::NamedTuple{(:title, :seriestype),Tuple{String,Symbol}}, ::typeof(plot), ::Array{String,1}, ::Array{String,1}, ::Vararg{Any,N} where N) at ./none:0",
      " [11] #heatmap#367(::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:title,),Tuple{String}}}, ::typeof(heatmap), ::Array{String,1}, ::Vararg{Any,N} where N) at /root/.julia/packages/RecipesBase/jcXIg/src/RecipesBase.jl:402",
      " [12] (::Plots.var\"#kw##heatmap\")(::NamedTuple{(:title,),Tuple{String}}, ::typeof(heatmap), ::Array{String,1}, ::Vararg{Any,N} where N) at ./none:0",
      " [13] top-level scope at In[33]:3"
     ]
    }
   ],
   "source": [
    "xs = [string(\"h\", i) for i = 1:16]\n",
    "ys = [string(\"w\", i) for i = 1:16]\n",
    "heatmap(xs, ys, \"YOUR CODE HERE\", title=\"Input gate weight used in W_input * prev_hidden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "colab_type": "code",
    "id": "OTQK5CVMSXCJ",
    "outputId": "ec3faf67-b3e7-47b5-a1d4-585127c2407a"
   },
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "Cannot convert String to series data for plotting",
      "",
      "Stacktrace:",
      " [1] error(::String) at ./error.jl:33",
      " [2] _prepare_series_data(::String) at /root/.julia/packages/RecipesPipeline/2pkja/src/series.jl:8",
      " [3] _series_data_vector(::String, ::Dict{Symbol,Any}) at /root/.julia/packages/RecipesPipeline/2pkja/src/series.jl:27",
      " [4] macro expansion at /root/.julia/packages/RecipesPipeline/2pkja/src/series.jl:140 [inlined]",
      " [5] apply_recipe(::Dict{Symbol,Any}, ::Type{RecipesPipeline.SliceIt}, ::Array{String,1}, ::Array{String,1}, ::String) at /root/.julia/packages/RecipesBase/jcXIg/src/RecipesBase.jl:281",
      " [6] _process_userrecipes!(::Plots.Plot{Plots.GRBackend}, ::Dict{Symbol,Any}, ::Tuple{Array{String,1},Array{String,1},String}) at /root/.julia/packages/RecipesPipeline/2pkja/src/user_recipe.jl:35",
      " [7] recipe_pipeline!(::Plots.Plot{Plots.GRBackend}, ::Dict{Symbol,Any}, ::Tuple{Array{String,1},Array{String,1},String}) at /root/.julia/packages/RecipesPipeline/2pkja/src/RecipesPipeline.jl:68",
      " [8] _plot!(::Plots.Plot{Plots.GRBackend}, ::Dict{Symbol,Any}, ::Tuple{Array{String,1},Array{String,1},String}) at /root/.julia/packages/Plots/V8QVi/src/plot.jl:167",
      " [9] #plot#124(::Base.Iterators.Pairs{Symbol,Any,Tuple{Symbol,Symbol},NamedTuple{(:title, :seriestype),Tuple{String,Symbol}}}, ::typeof(plot), ::Array{String,1}, ::Vararg{Any,N} where N) at /root/.julia/packages/Plots/V8QVi/src/plot.jl:57",
      " [10] (::RecipesBase.var\"#kw##plot\")(::NamedTuple{(:title, :seriestype),Tuple{String,Symbol}}, ::typeof(plot), ::Array{String,1}, ::Array{String,1}, ::Vararg{Any,N} where N) at ./none:0",
      " [11] #heatmap#367(::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:title,),Tuple{String}}}, ::typeof(heatmap), ::Array{String,1}, ::Vararg{Any,N} where N) at /root/.julia/packages/RecipesBase/jcXIg/src/RecipesBase.jl:402",
      " [12] (::Plots.var\"#kw##heatmap\")(::NamedTuple{(:title,),Tuple{String}}, ::typeof(heatmap), ::Array{String,1}, ::Vararg{Any,N} where N) at ./none:0",
      " [13] top-level scope at In[34]:3"
     ]
    }
   ],
   "source": [
    "xs = [string(\"x\", i) for i = 1:3]\n",
    "ys = [string(\"w\", i) for i = 1:16]\n",
    "heatmap(xs, ys, \"YOUR CODE HERE\", title=\"Input gate weight used in W_input * x_t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "colab_type": "code",
    "id": "dpII80AmScMC",
    "outputId": "b520c206-c7d2-42bc-cb12-4161ec951269"
   },
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "Cannot convert String to series data for plotting",
      "",
      "Stacktrace:",
      " [1] error(::String) at ./error.jl:33",
      " [2] _prepare_series_data(::String) at /root/.julia/packages/RecipesPipeline/2pkja/src/series.jl:8",
      " [3] _series_data_vector(::String, ::Dict{Symbol,Any}) at /root/.julia/packages/RecipesPipeline/2pkja/src/series.jl:27",
      " [4] macro expansion at /root/.julia/packages/RecipesPipeline/2pkja/src/series.jl:140 [inlined]",
      " [5] apply_recipe(::Dict{Symbol,Any}, ::Type{RecipesPipeline.SliceIt}, ::Array{String,1}, ::Array{String,1}, ::String) at /root/.julia/packages/RecipesBase/jcXIg/src/RecipesBase.jl:281",
      " [6] _process_userrecipes!(::Plots.Plot{Plots.GRBackend}, ::Dict{Symbol,Any}, ::Tuple{Array{String,1},Array{String,1},String}) at /root/.julia/packages/RecipesPipeline/2pkja/src/user_recipe.jl:35",
      " [7] recipe_pipeline!(::Plots.Plot{Plots.GRBackend}, ::Dict{Symbol,Any}, ::Tuple{Array{String,1},Array{String,1},String}) at /root/.julia/packages/RecipesPipeline/2pkja/src/RecipesPipeline.jl:68",
      " [8] _plot!(::Plots.Plot{Plots.GRBackend}, ::Dict{Symbol,Any}, ::Tuple{Array{String,1},Array{String,1},String}) at /root/.julia/packages/Plots/V8QVi/src/plot.jl:167",
      " [9] #plot#124(::Base.Iterators.Pairs{Symbol,Any,Tuple{Symbol,Symbol},NamedTuple{(:title, :seriestype),Tuple{String,Symbol}}}, ::typeof(plot), ::Array{String,1}, ::Vararg{Any,N} where N) at /root/.julia/packages/Plots/V8QVi/src/plot.jl:57",
      " [10] (::RecipesBase.var\"#kw##plot\")(::NamedTuple{(:title, :seriestype),Tuple{String,Symbol}}, ::typeof(plot), ::Array{String,1}, ::Array{String,1}, ::Vararg{Any,N} where N) at ./none:0",
      " [11] #heatmap#367(::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:title,),Tuple{String}}}, ::typeof(heatmap), ::Array{String,1}, ::Vararg{Any,N} where N) at /root/.julia/packages/RecipesBase/jcXIg/src/RecipesBase.jl:402",
      " [12] (::Plots.var\"#kw##heatmap\")(::NamedTuple{(:title,),Tuple{String}}, ::typeof(heatmap), ::Array{String,1}, ::Vararg{Any,N} where N) at ./none:0",
      " [13] top-level scope at In[35]:3"
     ]
    }
   ],
   "source": [
    "xs = [string(\"h\", i) for i = 1:16]\n",
    "ys = [string(\"w\", i) for i = 1:16]\n",
    "heatmap(xs, ys, \"YOUR CODE HERE\", title=\"Output gate weight used in W_output * prev_hidden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "colab_type": "code",
    "id": "fDt213WYScO3",
    "outputId": "bcdf0ff1-d197-4d18-ead5-20da6c8c0673"
   },
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "Cannot convert String to series data for plotting",
      "",
      "Stacktrace:",
      " [1] error(::String) at ./error.jl:33",
      " [2] _prepare_series_data(::String) at /root/.julia/packages/RecipesPipeline/2pkja/src/series.jl:8",
      " [3] _series_data_vector(::String, ::Dict{Symbol,Any}) at /root/.julia/packages/RecipesPipeline/2pkja/src/series.jl:27",
      " [4] macro expansion at /root/.julia/packages/RecipesPipeline/2pkja/src/series.jl:140 [inlined]",
      " [5] apply_recipe(::Dict{Symbol,Any}, ::Type{RecipesPipeline.SliceIt}, ::Array{String,1}, ::Array{String,1}, ::String) at /root/.julia/packages/RecipesBase/jcXIg/src/RecipesBase.jl:281",
      " [6] _process_userrecipes!(::Plots.Plot{Plots.GRBackend}, ::Dict{Symbol,Any}, ::Tuple{Array{String,1},Array{String,1},String}) at /root/.julia/packages/RecipesPipeline/2pkja/src/user_recipe.jl:35",
      " [7] recipe_pipeline!(::Plots.Plot{Plots.GRBackend}, ::Dict{Symbol,Any}, ::Tuple{Array{String,1},Array{String,1},String}) at /root/.julia/packages/RecipesPipeline/2pkja/src/RecipesPipeline.jl:68",
      " [8] _plot!(::Plots.Plot{Plots.GRBackend}, ::Dict{Symbol,Any}, ::Tuple{Array{String,1},Array{String,1},String}) at /root/.julia/packages/Plots/V8QVi/src/plot.jl:167",
      " [9] #plot#124(::Base.Iterators.Pairs{Symbol,Any,Tuple{Symbol,Symbol},NamedTuple{(:title, :seriestype),Tuple{String,Symbol}}}, ::typeof(plot), ::Array{String,1}, ::Vararg{Any,N} where N) at /root/.julia/packages/Plots/V8QVi/src/plot.jl:57",
      " [10] (::RecipesBase.var\"#kw##plot\")(::NamedTuple{(:title, :seriestype),Tuple{String,Symbol}}, ::typeof(plot), ::Array{String,1}, ::Array{String,1}, ::Vararg{Any,N} where N) at ./none:0",
      " [11] #heatmap#367(::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:title,),Tuple{String}}}, ::typeof(heatmap), ::Array{String,1}, ::Vararg{Any,N} where N) at /root/.julia/packages/RecipesBase/jcXIg/src/RecipesBase.jl:402",
      " [12] (::Plots.var\"#kw##heatmap\")(::NamedTuple{(:title,),Tuple{String}}, ::typeof(heatmap), ::Array{String,1}, ::Vararg{Any,N} where N) at ./none:0",
      " [13] top-level scope at In[36]:3"
     ]
    }
   ],
   "source": [
    "xs = [string(\"x\", i) for i = 1:3]\n",
    "ys = [string(\"w\", i) for i = 1:16]\n",
    "heatmap(xs, ys, \"YOUR CODE HERE\", title=\"Output gate weight used in W_output * x_t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "colab_type": "code",
    "id": "wnTf9zE7SgQ5",
    "outputId": "107252c4-d2f2-41de-8769-1d4c5cd8a7f7"
   },
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "Cannot convert String to series data for plotting",
      "",
      "Stacktrace:",
      " [1] error(::String) at ./error.jl:33",
      " [2] _prepare_series_data(::String) at /root/.julia/packages/RecipesPipeline/2pkja/src/series.jl:8",
      " [3] _series_data_vector(::String, ::Dict{Symbol,Any}) at /root/.julia/packages/RecipesPipeline/2pkja/src/series.jl:27",
      " [4] macro expansion at /root/.julia/packages/RecipesPipeline/2pkja/src/series.jl:140 [inlined]",
      " [5] apply_recipe(::Dict{Symbol,Any}, ::Type{RecipesPipeline.SliceIt}, ::Array{String,1}, ::Array{String,1}, ::String) at /root/.julia/packages/RecipesBase/jcXIg/src/RecipesBase.jl:281",
      " [6] _process_userrecipes!(::Plots.Plot{Plots.GRBackend}, ::Dict{Symbol,Any}, ::Tuple{Array{String,1},Array{String,1},String}) at /root/.julia/packages/RecipesPipeline/2pkja/src/user_recipe.jl:35",
      " [7] recipe_pipeline!(::Plots.Plot{Plots.GRBackend}, ::Dict{Symbol,Any}, ::Tuple{Array{String,1},Array{String,1},String}) at /root/.julia/packages/RecipesPipeline/2pkja/src/RecipesPipeline.jl:68",
      " [8] _plot!(::Plots.Plot{Plots.GRBackend}, ::Dict{Symbol,Any}, ::Tuple{Array{String,1},Array{String,1},String}) at /root/.julia/packages/Plots/V8QVi/src/plot.jl:167",
      " [9] #plot#124(::Base.Iterators.Pairs{Symbol,Any,Tuple{Symbol,Symbol},NamedTuple{(:title, :seriestype),Tuple{String,Symbol}}}, ::typeof(plot), ::Array{String,1}, ::Vararg{Any,N} where N) at /root/.julia/packages/Plots/V8QVi/src/plot.jl:57",
      " [10] (::RecipesBase.var\"#kw##plot\")(::NamedTuple{(:title, :seriestype),Tuple{String,Symbol}}, ::typeof(plot), ::Array{String,1}, ::Array{String,1}, ::Vararg{Any,N} where N) at ./none:0",
      " [11] #heatmap#367(::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:title,),Tuple{String}}}, ::typeof(heatmap), ::Array{String,1}, ::Vararg{Any,N} where N) at /root/.julia/packages/RecipesBase/jcXIg/src/RecipesBase.jl:402",
      " [12] (::Plots.var\"#kw##heatmap\")(::NamedTuple{(:title,),Tuple{String}}, ::typeof(heatmap), ::Array{String,1}, ::Vararg{Any,N} where N) at ./none:0",
      " [13] top-level scope at In[37]:3"
     ]
    }
   ],
   "source": [
    "xs = [string(\"h\", i) for i = 1:16]\n",
    "ys = [string(\"w\", i) for i = 1:16]\n",
    "heatmap(xs, ys, \"YOUR CODE HERE\", title=\"Change weight used in W_change * prev_hidden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "colab_type": "code",
    "id": "1XxlbQ-JSgTQ",
    "outputId": "7c8e9dda-fa10-4975-c40c-3db110b9d363"
   },
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "Cannot convert String to series data for plotting",
      "",
      "Stacktrace:",
      " [1] error(::String) at ./error.jl:33",
      " [2] _prepare_series_data(::String) at /root/.julia/packages/RecipesPipeline/2pkja/src/series.jl:8",
      " [3] _series_data_vector(::String, ::Dict{Symbol,Any}) at /root/.julia/packages/RecipesPipeline/2pkja/src/series.jl:27",
      " [4] macro expansion at /root/.julia/packages/RecipesPipeline/2pkja/src/series.jl:140 [inlined]",
      " [5] apply_recipe(::Dict{Symbol,Any}, ::Type{RecipesPipeline.SliceIt}, ::Array{String,1}, ::Array{String,1}, ::String) at /root/.julia/packages/RecipesBase/jcXIg/src/RecipesBase.jl:281",
      " [6] _process_userrecipes!(::Plots.Plot{Plots.GRBackend}, ::Dict{Symbol,Any}, ::Tuple{Array{String,1},Array{String,1},String}) at /root/.julia/packages/RecipesPipeline/2pkja/src/user_recipe.jl:35",
      " [7] recipe_pipeline!(::Plots.Plot{Plots.GRBackend}, ::Dict{Symbol,Any}, ::Tuple{Array{String,1},Array{String,1},String}) at /root/.julia/packages/RecipesPipeline/2pkja/src/RecipesPipeline.jl:68",
      " [8] _plot!(::Plots.Plot{Plots.GRBackend}, ::Dict{Symbol,Any}, ::Tuple{Array{String,1},Array{String,1},String}) at /root/.julia/packages/Plots/V8QVi/src/plot.jl:167",
      " [9] #plot#124(::Base.Iterators.Pairs{Symbol,Any,Tuple{Symbol,Symbol},NamedTuple{(:title, :seriestype),Tuple{String,Symbol}}}, ::typeof(plot), ::Array{String,1}, ::Vararg{Any,N} where N) at /root/.julia/packages/Plots/V8QVi/src/plot.jl:57",
      " [10] (::RecipesBase.var\"#kw##plot\")(::NamedTuple{(:title, :seriestype),Tuple{String,Symbol}}, ::typeof(plot), ::Array{String,1}, ::Array{String,1}, ::Vararg{Any,N} where N) at ./none:0",
      " [11] #heatmap#367(::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:title,),Tuple{String}}}, ::typeof(heatmap), ::Array{String,1}, ::Vararg{Any,N} where N) at /root/.julia/packages/RecipesBase/jcXIg/src/RecipesBase.jl:402",
      " [12] (::Plots.var\"#kw##heatmap\")(::NamedTuple{(:title,),Tuple{String}}, ::typeof(heatmap), ::Array{String,1}, ::Vararg{Any,N} where N) at ./none:0",
      " [13] top-level scope at In[38]:3"
     ]
    }
   ],
   "source": [
    "xs = [string(\"x\", i) for i = 1:3]\n",
    "ys = [string(\"w\", i) for i = 1:16]\n",
    "heatmap(xs, ys, \"YOUR CODE HERE\", title=\"Change weight used in W_change * x_t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "colab_type": "code",
    "id": "BCLNGuswSjxV",
    "outputId": "3651743d-d501-423e-f235-13ddac0c772f"
   },
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "Cannot convert String to series data for plotting",
      "",
      "Stacktrace:",
      " [1] error(::String) at ./error.jl:33",
      " [2] _prepare_series_data(::String) at /root/.julia/packages/RecipesPipeline/2pkja/src/series.jl:8",
      " [3] _series_data_vector(::String, ::Dict{Symbol,Any}) at /root/.julia/packages/RecipesPipeline/2pkja/src/series.jl:27",
      " [4] macro expansion at /root/.julia/packages/RecipesPipeline/2pkja/src/series.jl:140 [inlined]",
      " [5] apply_recipe(::Dict{Symbol,Any}, ::Type{RecipesPipeline.SliceIt}, ::Array{String,1}, ::Array{String,1}, ::String) at /root/.julia/packages/RecipesBase/jcXIg/src/RecipesBase.jl:281",
      " [6] _process_userrecipes!(::Plots.Plot{Plots.GRBackend}, ::Dict{Symbol,Any}, ::Tuple{Array{String,1},Array{String,1},String}) at /root/.julia/packages/RecipesPipeline/2pkja/src/user_recipe.jl:35",
      " [7] recipe_pipeline!(::Plots.Plot{Plots.GRBackend}, ::Dict{Symbol,Any}, ::Tuple{Array{String,1},Array{String,1},String}) at /root/.julia/packages/RecipesPipeline/2pkja/src/RecipesPipeline.jl:68",
      " [8] _plot!(::Plots.Plot{Plots.GRBackend}, ::Dict{Symbol,Any}, ::Tuple{Array{String,1},Array{String,1},String}) at /root/.julia/packages/Plots/V8QVi/src/plot.jl:167",
      " [9] #plot#124(::Base.Iterators.Pairs{Symbol,Any,Tuple{Symbol,Symbol},NamedTuple{(:title, :seriestype),Tuple{String,Symbol}}}, ::typeof(plot), ::Array{String,1}, ::Vararg{Any,N} where N) at /root/.julia/packages/Plots/V8QVi/src/plot.jl:57",
      " [10] (::RecipesBase.var\"#kw##plot\")(::NamedTuple{(:title, :seriestype),Tuple{String,Symbol}}, ::typeof(plot), ::Array{String,1}, ::Array{String,1}, ::Vararg{Any,N} where N) at ./none:0",
      " [11] #heatmap#367(::Base.Iterators.Pairs{Symbol,String,Tuple{Symbol},NamedTuple{(:title,),Tuple{String}}}, ::typeof(heatmap), ::Array{String,1}, ::Vararg{Any,N} where N) at /root/.julia/packages/RecipesBase/jcXIg/src/RecipesBase.jl:402",
      " [12] (::Plots.var\"#kw##heatmap\")(::NamedTuple{(:title,),Tuple{String}}, ::typeof(heatmap), ::Array{String,1}, ::Vararg{Any,N} where N) at ./none:0",
      " [13] top-level scope at In[39]:3"
     ]
    }
   ],
   "source": [
    "xs = [\"forget\", \"input\", \"output\", \"change\"]\n",
    "ys = [string(\"b\", i) for i = 1:16]\n",
    "heatmap(xs, ys, \"YOUR CODE HERE\", title=\"Bias vectors for gates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Y83S2VYSnpR"
   },
   "source": [
    "Now discuss the findings from the figures. You can further inspect the model to find the treasure hidden in the model.\n",
    "\n",
    "Your Comment:"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "JuliaOnColab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
