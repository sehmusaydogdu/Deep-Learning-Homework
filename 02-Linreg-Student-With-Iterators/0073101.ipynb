{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression on Housing Data\n",
    "In the first lab assignment, you played with Boston Housing Dataset. In this lab assignment, you are going to implement a linear regression model trained on Boston Housing Data by using Knet for the first time. We will take advantage of iterators, callable objects and automatic differentation mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not touch this cell\n",
    "# Necessary imports\n",
    "using Pkg; for p in (\"Knet\",\"AutoGrad\",\"Plots\",\"Images\",\"ImageMagick\"); haskey(Pkg.installed(),p) || Pkg.add(p); end\n",
    "using Knet\n",
    "using Statistics\n",
    "using Random\n",
    "using Test\n",
    "import Base: length, size, iterate, eltype, IteratorSize, IteratorEltype, haslength, @propagate_inbounds, repeat, rand, tail\n",
    "import .Iterators: cycle, Cycle, take\n",
    "using Plots; default(fmt=:png,ls=:auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Reading\n",
    "You do not need to worry about data reading and preprocessing: We are going to take advantage of housing data reader which is also a part of Knet. We include some source file and then use ```housing``` function. ```housing``` function takes one input argument: the percentage of the test set to split dataset into two parts. Just take a look at the cell below. In this lab session, we are going to use 20% of the data as test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-0.410442951130207 -0.11370556630644414 … -0.32875762699414984 -0.41501073511771897; -0.4872401872268264 -0.4872401872268264 … 0.37030254229238807 2.9429307308500317; … ; 0.37599013494349426 -0.06817504645565328 … 0.3000822506747866 0.4406158949991036; 0.18581785870133055 -0.0018293136231862705 … 0.299246373315404 -0.3379138013685896], [26.4 16.1 … 30.7 19.4], [-0.40098999831716037 -0.416566269598577 … -0.40370578945862845 -0.40547756415879854; 0.4560568152443095 -0.4872401872268264 … -0.4872401872268264 1.4422309541914062; … ; 0.19755731607809054 0.41772304101330315 … 0.4406158949991036 0.2866094227309898; -0.4387391476922107 -0.29310253633586913 … 0.44628333670401804 -1.1333137556993775], [24.5 18.5 … 20.3 29.8])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do not touch this cell\n",
    "# Load data\n",
    "include(joinpath(Knet.dir(), \"data\", \"housing.jl\"))\n",
    "Knet.seed!(1)\n",
    "xtrn, ytrn, xtst, ytst = housing(0.20; url=\"https://raw.githubusercontent.com/ilkerkesen/ufldl-tutorial/master/ex1/housing.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13, 405), (1, 405), (13, 101), (1, 101))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print size of data matrices for testing\n",
    "size(xtrn), size(ytrn), size(xtst), size(ytst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minibatching via Iterators\n",
    "In this part, you are going implement a minibatching procedure (or let's call it pipeline). Remember, you need to implement your own ```minibatch``` function, it's forbidden to use Knet's ```minibatch``` procedure. Also, your minibatching scheme must use iterators. Just take a look at [this blog post](https://julialang.org/blog/2018/07/iterators-in-julia-0.7). To implement your minibatching pipeline, we provide you ```HousingData``` struct definition. Different from the original implementation, you are not going to discard the last remaining smaller minibatch, you will use all the instances. Also, remember that, ```HousingData``` structure is not mutable which means you are not able to change the values inside struct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not touch this cell\n",
    "# HousingDataMinibatch struct definition\n",
    "# As default, this struct definition also creates the following constructor,\n",
    "#   HousingDataMinibatch(x, y, batchsize, shuffle, ninstances)\n",
    "# where x is input data, y is output data, batchsize is number of samples in\n",
    "# a minibatch, shuffle is a boolean property which indicates shuffling\n",
    "# instances or not, ninstances is number of instances in the whole data split.\n",
    "# This constructor returns a HousingDataMinibatch object.\n",
    "struct HousingDataMinibatch\n",
    "    x\n",
    "    y\n",
    "    batchsize\n",
    "    shuffle # shuffle data in each epoch or not\n",
    "    ninstances # number of instances\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HousingDataMinibatch"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HousingDataMinibatch(x, y; batchsize=100, dtype=Array{Float64}, shuffle=false)\n",
    "#\n",
    "# Creates a HousingDataMinibatch object. It takes two positional arguments, x\n",
    "# and y, input and output data for the data split. It also take three optional\n",
    "# keyword arguments: batchsize (number of instances in a minibatch), dtype\n",
    "# (data type for minibatch arrays) and shuffle (if true, shuffle instances).\n",
    "function HousingDataMinibatch(x, y; batchsize=100, dtype=Array{Float64}, shuffle=false)\n",
    "    ninstances = size(x)[end]\n",
    "    data = HousingDataMinibatch(convert(dtype, x), convert(dtype, y), batchsize, shuffle, ninstances)\n",
    "    return data\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests for ```HousingDataMinibatch(x, y; ...)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: constructor tests passed\n",
      "└ @ Main In[6]:11\n"
     ]
    }
   ],
   "source": [
    "x1 = randn(5, 100); y1 = rand(1, 100)\n",
    "obj1 = HousingDataMinibatch(\n",
    "    x1, y1; batchsize=20, dtype=Array{Float32}, shuffle=true)\n",
    "@test obj1.shuffle == true\n",
    "@test typeof(obj1.x) <: Array{Float32}\n",
    "@test typeof(obj1.y) <: Array{Float32}\n",
    "@test obj1.batchsize == 20\n",
    "@test obj1.ninstances == 100\n",
    "@test abs2(sum(obj1.x - x1)) < 1e-6\n",
    "@test abs2(sum(obj1.y - y1)) < 1e-6\n",
    "@info \"constructor tests passed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "length (generic function with 157 methods)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# length(d)\n",
    "# Returns how many batches the dataset (d) has.\n",
    "# Hint: You can use divrem function. Type ?divrem to see how to use.\n",
    "function length(d::HousingDataMinibatch)\n",
    "    d, r = divrem(d.ninstances, d.batchsize)\n",
    "    return r == 0 ? d : d+1\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests for ```length(d::HousingDataMinibatch)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: length tests passed\n",
      "└ @ Main In[8]:5\n"
     ]
    }
   ],
   "source": [
    "x1 = randn(5, 100); y1 = rand(1, 100)\n",
    "test_helper1(batchsize) = HousingDataMinibatch(x1,y1; batchsize=batchsize)\n",
    "objects = [test_helper1(batchsize) for batchsize in (20, 30, 50, 100, 101)]\n",
    "@test map(length, objects) == [5, 4, 2, 1, 1]\n",
    "@info \"length tests passed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iterate (generic function with 294 methods)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iterate(d, state)\n",
    "# Takes a HousingDataMinibatch object as d and list of integers as state.\n",
    "# Returns one minibatch.\n",
    "# This is how you implement your own iterator!\n",
    "function iterate(d::HousingDataMinibatch, state=ifelse(\n",
    "    d.shuffle, randperm(d.ninstances), collect(1:d.ninstances)))\n",
    "    n = length(state)\n",
    "    n == 0 && return nothing\n",
    "    batchsize = min(d.batchsize, n)\n",
    "    indices, new_state = state[1:batchsize], state[batchsize+1:end]\n",
    "    x, y = d.x[:, indices], d.y[:, indices]\n",
    "    return ((x,y), new_state)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HousingDataMinibatch([-0.40098999831716037 -0.416566269598577 … -0.40370578945862845 -0.40547756415879854; 0.4560568152443095 -0.4872401872268264 … -0.4872401872268264 1.4422309541914062; … ; 0.19755731607809054 0.41772304101330315 … 0.4406158949991036 0.2866094227309898; -0.4387391476922107 -0.29310253633586913 … 0.44628333670401804 -1.1333137556993775], [24.5 18.5 … 20.3 29.8], 100, false, 101)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrn = HousingDataMinibatch(xtrn, ytrn; shuffle=true)\n",
    "dtst = HousingDataMinibatch(xtst, ytst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests for ```iterate``` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: iterate tests passed\n",
      "└ @ Main In[11]:9\n"
     ]
    }
   ],
   "source": [
    "x1 = randn(5, 100); y1 = rand(1, 100)\n",
    "test_helper2(batchsize) = HousingDataMinibatch(x1,y1; batchsize=batchsize)\n",
    "test_helper3(batches) = mapreduce(bi->size(bi[2],2), +, batches)\n",
    "objects = [test_helper1(batchsize) for batchsize in (20, 30, 50, 100, 101)]\n",
    "data_arrays = map(collect, objects)\n",
    "num_instances = map(test_helper3, data_arrays)\n",
    "@test map(length, data_arrays) == map(length, objects)\n",
    "@test prod(num_instances .== 100) == 1\n",
    "@info \"iterate tests passed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Implementation via Callable Objects\n",
    "Next, we are going to implement our model via callable objects. In Julia, we can call objects. Just give a glimpse at the following code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World!\n",
      "Hello, Jupiter!\n"
     ]
    }
   ],
   "source": [
    "struct Hello\n",
    "    planet\n",
    "    Hello(planet=\"World\") = new(planet)\n",
    "end\n",
    "\n",
    "(obj::Hello)() = println(\"Hello, $(obj.planet)!\")\n",
    "\n",
    "hello_world = Hello()\n",
    "hello_world()\n",
    "\n",
    "hello_jupiter = Hello(\"Jupiter\")\n",
    "hello_jupiter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assingment, you just need to define a linear layer and that's all! Write your solutions to the below cell. Hint: You need to use ```Param``` method of AutoGrad. Just type ```@doc Param``` to see the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(P(Array{Float64,2}(1,13)), P(Array{Float64,2}(1,1)))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct Linear\n",
    "    # Your code here\n",
    "    #w ile b olacak\n",
    "    w::Param\n",
    "    b::Param\n",
    "end\n",
    "\n",
    "function (l::Linear)(x)\n",
    "    # Your code here\n",
    "    # wx+b (forward called)\n",
    "    l.w * x .+ l.b\n",
    "end\n",
    "\n",
    "function Linear(xsize::Int, ysize::Int, atype=Array{Float64}, scale=0.1)\n",
    "    # Your code here\n",
    "    # w, b initialized\n",
    "    w = scale * randn(ysize,xsize)\n",
    "    b = zeros(ysize,1)\n",
    "    Linear(Param(convert(atype,w)),Param(convert(atype,b)))\n",
    "end\n",
    "\n",
    "model = Linear(13, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests for ```Linear```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Linear tests passed\n",
      "└ @ Main In[14]:10\n"
     ]
    }
   ],
   "source": [
    "test_model = Linear(5,3)\n",
    "test_data = rand(5,10)\n",
    "@test fieldnames(Linear) == (:w, :b)\n",
    "@test typeof(test_model.w) <: Param\n",
    "@test typeof(test_model.b) <: Param\n",
    "@test size(test_model.w) == (3,5)\n",
    "@test size(test_model.b) == (3,1)\n",
    "@test sum(test_model.b.value) ≈ 0.0\n",
    "@test size(test_model(test_data)) == (3,10)\n",
    "@info \"Linear tests passed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Loss Function\n",
    "In this part, we'll define our loss function. We are going to use minimum squared error loss function,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MSE](http://web.itu.edu.tr/keseni/mse.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to define three diffent functions for this purpose,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. A function takes predictions and gold values as input.\n",
    "2. A callable object procedure that takes input/output pair as input\n",
    "3. A callable object procedure that takes our dataset object as input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See function prototypes below and the documentation of ```train!``` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - takes predictions and gold values as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mse (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mse(ypred, ygold)\n",
    "    # Your code here\n",
    "    loss = (1/(2*size(ypred,2))) * sum((ypred .- ygold) .^2)\n",
    "    return loss\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - callable object procedure that takes input/output pair as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (m::Linear)(x, y)\n",
    "    # Your code here\n",
    "    model = Linear(size(x,1),size(y,1))\n",
    "    ypred = model(x)\n",
    "    loss  = mse(ypred,y)\n",
    "    return loss\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - callable object procedure that takes our dataset object as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (m::Linear)(data::HousingDataMinibatch)\n",
    "    # Your code here\n",
    "    mean(m(x,y) for (x,y) in data)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests for ```mse```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\u001b[1mTest Failed\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[20]:8\u001b[22m\n",
      "  Expression: test_model(test_data) ≈ mse(y2, y1)\n",
      "   Evaluated: 0.20083196582495438 ≈ 0.20099337662902703\n"
     ]
    },
    {
     "ename": "Test.FallbackTestSetException",
     "evalue": "There was an error during testing",
     "output_type": "error",
     "traceback": [
      "There was an error during testing",
      "",
      "Stacktrace:",
      " [1] record(::Test.FallbackTestSet, ::Test.Fail) at D:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.3\\Test\\src\\Test.jl:730",
      " [2] do_test(::Test.Returned, ::Expr) at D:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.3\\Test\\src\\Test.jl:519",
      " [3] top-level scope at In[20]:8"
     ]
    }
   ],
   "source": [
    "x1 = randn(5, 100); y1 = rand(1, 100); batchsize = 20\n",
    "test_data = HousingDataMinibatch(x1,y1; batchsize=batchsize, shuffle=false)\n",
    "test_model = Linear(5, 1)\n",
    "batch = take(test_data,1)\n",
    "w1, b1 = test_model.w.value, test_model.b.value\n",
    "y2 = w1 * x1 .+ b1\n",
    "@test mse(y2,y1) ≈ 0.5mean(abs2.(y1 - y2))\n",
    "@test test_model(test_data) ≈ mse(y2,y1)\n",
    "@info \"mse tests passed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with Modular Interface and Iterators\n",
    "Now, let's implement a ```mytrain!``` procedure to train our network! It takes model, train data, test data, report period (in iterations) and number of maximum iterations. It trains our model until a certain maximum iterations number, records loss values of train and test data splits after each report period. It should output three lists: iterations numbers, loss values of train set, loss values of test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: You will need ```sgd!```, ```cycle``` and ```take``` procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function mytrain!(m::Linear, dtrn, dtst, valid=10, max_iters=500)\n",
    "    # Your code here\n",
    "    return 0:valid:max_iters, trnloss, tstloss\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's train our network and plot the results,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Knet.seed!(42)\n",
    "model = Linear(13, 1)\n",
    "dtrn = HousingDataMinibatch(xtrn, ytrn; shuffle=true)\n",
    "dtst = HousingDataMinibatch(xtst, ytst)\n",
    "iters, trnloss, tstloss = mytrain!(model, dtrn, dtst)\n",
    "plot(iters, [trnloss, tstloss], labels=[:trn, :tst], xlabel=\"iterations\", ylabel=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 3
}
